{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbcf1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import boto3\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c78a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "AWS_ACCESS_KEY_ID = os.getenv('aws_access_key_id')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('aws_secret_access_key')\n",
    "ENDPOINT_URL = os.getenv('endpoint_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cf05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    #model_name: str = \"facebook/opt-30b\"\n",
    "    model_name: str = \"gpt2\"\n",
    "    # Path to HuggingFace cache directory. Default is ~/.cache/huggingface/.\n",
    "    cache_dir: Optional[str] =  '/data/modelcache/test/hub' #None\n",
    "    # Path to the directory that actually holds model files.\n",
    "    # e.g., ~/.cache/huggingface/models--facebook--opt-30b/snapshots/xxx/\n",
    "    # If this path is not None, we skip download models from HuggingFace.\n",
    "    repo_root: Optional[str] = None\n",
    "    # This is how many DeepSpeed-inference replicas to run for\n",
    "    # this batch inference job.\n",
    "    num_worker_groups: int = 1\n",
    "    # Number of DeepSpeed workers per group.\n",
    "    num_workers_per_group: int = 8\n",
    "\n",
    "    batch_size: int = 1\n",
    "    dtype: str = \"float16\"\n",
    "    # Maximum number of tokens DeepSpeed inference-engine can work with,\n",
    "    # including the input and output tokens.\n",
    "    max_tokens: int = 1024\n",
    "    # Use meta tensors to initialize model.\n",
    "    use_meta_tensor: bool = True\n",
    "    # Use cache for generation.\n",
    "    use_cache: bool = True\n",
    "    # The path for which we want to save the loaded model with a checkpoint.\n",
    "    save_mp_checkpoint_path: Optional[str] = None\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc0e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv()\n",
    "\n",
    "#AWS_ACCESS_KEY_ID = os.getenv('aws_access_key_id')\n",
    "#AWS_SECRET_ACCESS_KEY = os.getenv('aws_secret_access_key')\n",
    "\n",
    "#ENDPOINT_URL = 'http://10.0.0.179:30387'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4edcc55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hub/models--gpt2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder = f\"hub/models--{config.model_name.replace('/', '--')}\"\n",
    "model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f50d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3 = boto3.resource('s3',\n",
    "    endpoint_url = ENDPOINT_URL,\n",
    "    aws_access_key_id = AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c65e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_model_folder(bucket_name, s3_folder):\n",
    "    # Get bucket object\n",
    "    my_bucket = s3.Bucket('models')\n",
    "    # Iterate over objects in bucket\n",
    "    for obj in my_bucket.objects.filter(Prefix=model_folder):\n",
    "        print(obj)\n",
    "        \n",
    "#list_model_folder('models', model_folder)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c791db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"\n",
    "    Download the contents of a folder directory\n",
    "    Args:\n",
    "        bucket_name: the name of the s3 bucket\n",
    "        s3_folder: the folder path in the s3 bucket\n",
    "        local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        if not os.path.exists(target):\n",
    "            bucket.download_file(obj.key, target)\n",
    "            print('downloading: '+target)\n",
    "        else:\n",
    "            print('exists: '+target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631cc6aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: /data/modelcache/test/hub/blobs/10c66461e4c109db5a2196bff4bb59be30396ed8\n",
      "downloading: /data/modelcache/test/hub/blobs/1ceafd82e733dd4b21570b2a86cf27556a983041806c033a55d086e0ed782cd3\n",
      "downloading: /data/modelcache/test/hub/blobs/1f1d9aaca301414e7f6c9396df506798ff4eb9a6\n",
      "downloading: /data/modelcache/test/hub/blobs/226b0752cac7789c48f0cb3ec53eda48b7be36cc\n",
      "downloading: /data/modelcache/test/hub/blobs/3dc481ecc3b2c47a06ab4e20dba9d7f4b447bdf3\n",
      "downloading: /data/modelcache/test/hub/blobs/4b988bccc9dc5adacd403c00b4704976196548f8\n",
      "downloading: /data/modelcache/test/hub/blobs/602b71f15d40ed68c5f96330e3f3175a76a32126\n",
      "downloading: /data/modelcache/test/hub/blobs/7c5d3f4b8b76583b422fcb9189ad6c89d5d97a094541ce8932dce3ecabde1421\n",
      "downloading: /data/modelcache/test/hub/blobs/a16a55fda99d2f2e7b69cce5cf93ff4ad3049930\n",
      "downloading: /data/modelcache/test/hub/blobs/adf0adedbf4016b249550f866c66a3b3a3d09c8b3b3a1f6e5e9a265d94e0270e\n",
      "downloading: /data/modelcache/test/hub/blobs/c966da3b74697803352ca7c6f2f220e7090a557b619de9da0c6b34d89f7825c1\n",
      "downloading: /data/modelcache/test/hub/blobs/cfcd510b239d90b71ee87d4e57a5a8c2d55b2a941e5d9fe5852298268ddbe61b\n",
      "downloading: /data/modelcache/test/hub/refs/main\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/.gitattributes\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/64-8bits.tflite\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/64-fp16.tflite\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/64.tflite\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/README.md\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/pytorch_model.bin\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/rust_model.ot\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
      "downloading: /data/modelcache/test/hub/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
      "model downloaded in: 333.4784061908722\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "download_s3_folder('models', model_folder, config.cache_dir)\n",
    "end = time.time()\n",
    "print(f'model downloaded in: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65081f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
