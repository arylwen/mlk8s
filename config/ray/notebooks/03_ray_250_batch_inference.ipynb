{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e19c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc3bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "RAY_CLIENT_URL = os.getenv('ray_client_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eee26d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.15</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.5.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.1.64.45:8265\" target=\"_blank\">http://10.1.64.45:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='10.1.64.45:8265', python_version='3.9.15', ray_version='2.5.0', ray_commit='142b462d5e31c42b7d888e222cab2424d962db3c', protocol_version='2022-12-06', _num_clients=2, _context_to_restore=<ray.util.client._ClientContext object at 0x7f8553ce3700>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python versions must match on client and server: 3.9.15\n",
    "ray.init(\n",
    "    address=RAY_CLIENT_URL,\n",
    "    namespace=\"kuberay\",\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"accelerate>=0.16.0\",\n",
    "            \"transformers>=4.26.0\",\n",
    "            \"numpy<1.24\",  \n",
    "            \"torch\",            \n",
    "        ],\n",
    "        \"env_vars\": {\n",
    "            \"HF_HUB_DISABLE_PROGRESS_BARS\": \"1\",\n",
    "#            commenting this improves inference by 20%\n",
    "#            \"RAY_worker_register_timeout_seconds\":\"600\", \n",
    "        }\n",
    "    },\n",
    "    _system_config={\n",
    "#        these settings have no effect on the infernce time\n",
    "#        \"num_heartbeats_timeout\":300,\n",
    "#        \"kill_idle_workers_interval_ms\":0,\n",
    "#        \"idle_worker_killing_time_threshold_ms\":100000000,\n",
    "#        \"kill_idle_workers_of_terminated_job\":False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb20dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.data.context.DatasetContext.get_current().use_streaming_executor = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb83f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \"\n",
    "    \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \"\n",
    "    \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed66a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-24 13:27:37,095 I 20792 20792] logging.cc:230: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to -1\n",
      "2023-06-24 13:27:37,402\tWARNING dataset.py:253 -- \u001b[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\n",
      "\n",
      "Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import ray.data\n",
    "import pandas as pd\n",
    "\n",
    "ds = ray.data.from_pandas(pd.DataFrame([prompt], columns=[\"prompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910ccb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=10)\n",
    "class PredictCallable:\n",
    "\n",
    "    def __init__(self, model_id: str, revision: str = None):\n",
    "        print('__init__')\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "        import torch\n",
    "\n",
    "        start = time.time()\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            revision=revision,\n",
    "#            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "#           device_map=\"auto\",  # automatically makes use of all GPUs available to the Actor\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model.tie_weights()\n",
    "        end = time.time()\n",
    "        print(f'model loaded successfully in: {end-start}s')\n",
    "\n",
    "    def __call__(self, batch: pd.DataFrame) -> pd.DataFrame:\n",
    "        print('__call__')        \n",
    "\n",
    "        tokenized = self.tokenizer(\n",
    "            list(batch[\"prompt\"]), return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids = tokenized.input_ids.to(self.model.device)\n",
    "        attention_mask = tokenized.attention_mask.to(self.model.device)\n",
    "\n",
    "        gen_tokens = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "            max_length=100,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "        return pd.DataFrame(\n",
    "            self.tokenizer.batch_decode(gen_tokens), columns=[\"responses\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf2ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = PredictCallable.remote(model_id=\"EleutherAI/gpt-j-6B\", revision = \"float16\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47146a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = actor.__call__.remote(pd.DataFrame([prompt], columns=[\"prompt\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28287928",
   "metadata": {},
   "source": [
    "#### Load model time: 23s\n",
    "\n",
    "-  1 cpus - 230 s / 182 s / model - 42 s\n",
    "-  5 cpus - 111 s\n",
    "-  8 cpus - 111s / 65 s \n",
    "-  9 cpus - 91 s / 54 s\n",
    "- 10 cpus - 89 s / 54 s\n",
    "- 15 cpus - 89 s\n",
    "- 25 cpus - 89 s \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae803c40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=10.1.232.31)\u001b[0m [2023-06-24 13:27:38,528 I 6478 6478] logging.cc:230: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PredictCallable pid=6478, ip=10.1.232.31)\u001b[0m __init__\n",
      "\u001b[2m\u001b[36m(PredictCallable pid=6478, ip=10.1.232.31)\u001b[0m model loaded successfully in: 21.541340827941895s\n",
      "\u001b[2m\u001b[36m(PredictCallable pid=6478, ip=10.1.232.31)\u001b[0m __call__\n",
      "inference time: 72.03734827041626s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gen = ray.get(future)\n",
    "end = time.time()\n",
    "print(f'inference time: {end-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d503d2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a shocking finding, scientists discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\\n\\n\"The most striking thing about the first herd of unicorns we discovered in the Peruvian rainforests is that the animals speak English, and no one knew that unicorns lived in the U.S. until that moment,‚Äù said Dr. Frank Z'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d837c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PredictCallable pid=6478, ip=10.1.232.31)\u001b[0m __call__\n",
      "inference time: 37.454341411590576s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In a shocking finding, scientists discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\\n\\nThe valley is in the Puna de Atacama region of Chile, an area noted for its high atmospheric salt content, the researchers said, which makes it a perfect climate for the plants and animals in the area.\\n\\nThis particular valley was known to have'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future = actor.__call__.remote(pd.DataFrame([prompt], columns=[\"prompt\"]))\n",
    "start = time.time()\n",
    "gen = ray.get(future)\n",
    "end = time.time()\n",
    "print(f'inference time: {end-start}s')\n",
    "gen.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa560f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643006b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
