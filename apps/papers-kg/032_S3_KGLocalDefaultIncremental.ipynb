{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Index \n",
    "## S3 storage\n",
    "### Default llama index KG prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "from pyvis.network import Network\n",
    "\n",
    "import sys\n",
    "#kron extensions to llama_index to support openai compatible api\n",
    "sys.path.append('../llama-index/')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "import openai\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-48characterstofakeanopenaikey48charactersopenai0\"\n",
    "os.environ['OPENAI_API_BASE'] = \"http://10.0.0.222:30307/v1\"\n",
    "openai.api_key = \"sk-48characterstofakeanopenaikey48charactersopenai0\"\n",
    "openai.api_base = \"http://10.0.0.222:30307/v1\"\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "AWS_ACCESS_KEY_ID = os.environ['AF_AWS_ACCESS_KEY_ID'] \n",
    "AWS_SECRET_ACCESS_KEY = os.environ['AF_AWS_SECRET_ACCESS_KEY'] \n",
    "#AWS_DEFAULT_REGION = os.environ['AF_AWS_DEFAULT_REGION'] \n",
    "AWS_ENDPOINT_URL = os.environ['AF_AWS_ENDPOINT_URL'] \n",
    "\n",
    "model = \"Writer/camel-5b-hf\"\n",
    "#model = \"mosaicml/mpt-7b-instruct\"\n",
    "#model = \"mosaicml/mpt-30b-instruct\"\n",
    "\n",
    "CORPUS = 'ArxivHealthcareNLP'\n",
    "#CORPUS = 'arxiv_cl'\n",
    "\n",
    "INDEX_NAME = f\"{model.replace('/', '-')}-default-no-coref\"\n",
    "#INDEX_NAME = f\"{model.replace('/', '-')}-default-coref\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index import StorageContext\n",
    "from llama_index import SimpleDirectoryReader, ServiceContext\n",
    "from llama_index import KnowledgeGraphIndex\n",
    "from llama_index.graph_stores import SimpleGraphStore \n",
    "from llama_index import load_index_from_storage \n",
    "from llama_index.langchain_helpers.text_splitter import SentenceSplitter\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "#extensions to llama_index to support openai compatible endpoints, e.g. llama-api\n",
    "from kron.llm_predictor.KronOpenAILLM import KronOpenAI\n",
    "from kron.llm_predictor.KronLLMPredictor import KronLLMPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer/camel uses endoftext \n",
    "def monkey_patch_global_helper_tokenizer():\n",
    "    from llama_index.utils import globals_helper\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    tokenizer = lambda text: enc.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    globals_helper._tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents = SimpleDirectoryReader(TXT_BASE, filename_as_id=True).load_data()\n",
    "from kron.readers import S3Reader\n",
    "\n",
    "s3_prefix = 'dags/ArxivHealthcareNLP/txt_cleaned/publicdomain'\n",
    "\n",
    "def load_documents(s3_prefix):\n",
    "    license = s3_prefix.split('/')[-1]\n",
    "\n",
    "    loader = S3Reader(\n",
    "                    bucket='papers-kg', \n",
    "                    prefix=s3_prefix, \n",
    "                    filename_as_id = True,\n",
    "                    aws_access_id=AWS_ACCESS_KEY_ID, \n",
    "                    aws_access_secret=AWS_SECRET_ACCESS_KEY,\n",
    "                    s3_endpoint_url = AWS_ENDPOINT_URL,\n",
    "                    file_metadata = lambda x: {'license': license},\n",
    "                )\n",
    "    documents = loader.load_data()\n",
    "    return documents\n",
    "\n",
    "documents = load_documents(s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='2211.01705v1.A_speech_corpus_for_chronic_kidney_disease', embedding=None, metadata={'license': 'publicdomain'}, excluded_embed_metadata_keys=['license'], excluded_llm_metadata_keys=['license'], relationships={}, hash='56df9c2451410ff42336601c4e8f4dd4f9338fefeaf74cad63f875a476e431a9', text=\"Jihyun Mun1,Sunhee Kim2,Myeong Ju Kim3,Jiwon Ryu4,Sejoong Kim3,Minhwa Chung1 1Department of Linguistics,Seoul National University,Republic of Korea 2Department of French Language Education,Seoul National University,Republic of Korea 3Center for Artificial Intelligence in Healthcare,Seoul National University,Republic of Korea 4Department of Internal Medicine,Seoul National University Bundang Hospital,Republic of Korea 5Department of Internal Medicine,Seoul National University College of Medicine,Republic of Korea In this study,authors present speech corpus of patients with chronic kidney disease CKD that will be used for research on pathological voice analysis,automatic illness identification,and severity prediction.This paper introduces steps involved in creating this corpus,including choice of speech-related parameters and speech lists as well as recording technique. speakers in this corpus,CKD patients with varying degrees of severity who were categorized based on estimated glomerular filtration rate eGFR ,delivered sustained vowels,sentence,and paragraph stimuli.This study compared and analyzed voice characteristics of CKD patients with those of control group results revealed differences in voice quality,phoneme-level pronunciation,prosody, glottal source,and aerodynamic parameters. Index Terms corpus development,chronic kidney disease INTRODUCTION continuous decline in kidney function and structural damage to kidneys are characteristics of chronic kidney disease CKD. CKD is serious condition with high prevalence around world that,if not detected and treated promptly,requires renal replacement therapy,such as dialysis. there may not be any symptoms in early stages of disease,blood and urine tests are still required to diagnose CKD,so awareness of condition is still low.Therefore, new index that can both diagnose disease and gauge its severity should be created.It should be non-invasive and simple to repeat. CKD affects variety of bodily systems, respiratory system,as well as cardiovascular,neurological, musculoskeletal,immunological,endocrine,and metabolic systems. lungs and kidneys both contribute to maintaining body' acid-base balance in both healthy and diseased states,therefore any changes to renal system will affect respiratory system and vice versa. strength and endurance of respiratory muscles are significantly reduced in CKD patients compared to non-CKD persons,and potency of laryngeal and respiratory muscles is severely compromised. characteristics of end-stage renal disease ESRD ,which include buildup of uremic toxins,an acid-base imbalance,and volume overload,are known to cause diminished lung function and vocal fold edema.As respiration is primary source of speech ,analyzing voice characteristics of CKD patients and automatically detecting and predicting severity of CKD through speech may be useful in early diagnosis and effective treatment of CKD. Tables and show parameters,stimuli,and participants of previous studies,and analysis results of CKD voice analysis..Parameters,stimuli,and participants in previous, ipipi, Non-CKD vs.CKD vs.HD Non-CKD vs.HD , Non-CKD vs.CKD.CKD voice analysis results, Previous research identified voice difference between speakers with and without CKD,as demonstrated in Tables. Finding out characteristics of CKD voice was challenging, though,because results were varied.,they only looked at small number of speech-related features using limited voice data. results,however,can differ since variables they looked at can be evaluated in sentences rather than only in continuous vowel sounds.,because CKD can alter various parts of speech,it is necessary to examine speech using variety of metrics.It is difficult to understand how CKD affects voice and how voice changes based on stage of CKD because they did not identify CKD group according to stage.,no research used automatic detection or severity prediction methods for CKD,nor was there corpus that gathered voices of CKD patients.Therefore, speech corpus containing different speech data and participants' information connected to their stage of CKD is needed to understand voice change in CKD patients and construct an appropriate index. With this goal,this paper introduces corpus which is developed for studying CKD voice,automatically detecting disease, and predicting severity is introduced.This paper is organized as follows Section describes corpus,including participants, metadata,reading script,and recording procedure.Section presents parameters which are used to analyze CKD voice, and results discussion,which are followed by conclusion in Section..CORPUS.Participants and metadata In total,CKD speakers and non-CKD speakers were recruited by us.All of speakers were chosen from Bundang Hospital at Seoul National University. ages of CKD speakers ranged from to ,with an average of standard deviation.,and their severity levels were established according to doctor' assessment based on eGFR estimated glomerular filtration rate. ages of non-CKD speakers ranged from to ,with an average of.std.displays number of speakers by severity and gender.Some speakers have been recorded multiple times, and speech data from these speakers will be used in longitudinal study to examine how voice changes as disease progresses. exclusion criteria included smoking, asthma,and chronic obstructive pulmonary disease,as well as presence of vocal cord disease and its history.After recruiting speakers,authors collected metadata of participants. following information is gathered as meta-data language disorder presence, gender,birthdate,place of residence,presence and kind of comorbidities,medication usage,physical conditions at time of recording..Number of speakers.Reading script First,as in previous studies,participants are required to sustain vowel. vowel with highest first formant, ,does not significantly increase first or second harmonics.Vowel speech can be used to extract voice quality features,pitch features, glottal source parameters,and maximum phonation time MPT. Second,they are required to read text made up entirely of vocal sounds.This sentence speech can be used to extract voice quality features and pitch features as in vowel speech because it only contains voiced sounds.Authors want to examine how these features are represented in sentences.,they were required to read paragraph made up of six phonetically balanced sentences that varied in length.Spectral features,prosodic features,and phoneme,level pronunciation features are all extracted from paragraph speech..Recording procedure Seoul National University Bundang Hospital served as site of recording.For recording purposes, Samsung Galaxy series smartphone and an AKG C414 B-ULS microphone with an AKG PF80 pop filter were both used. Scarlett Solo Audio Interface was utilized to convert microphone signals into computerreadable format.To prevent air puffing, smartphone and microphone were situated cm from speaker.guide led speaker through process during each recording session, instructing them to wait for at least three seconds in between each sentence and to re-record any sentences that drastically varied from prompt.All speakers were asked to speak naturally and to help them do so,they recorded sample sentence that started with greetings and self-introductions. speech was recorded as WAV file with 16kHz sampling rate.Authors segmented utterances into separate WAV files when recording was done,and Praat did this..ANALYSIS RESULTS.Methods Authors examined voices of speakers up to CKD stage because number of hemodialyses,renal transplantation,and CKD stage speakers was quite low in comparison to speakers at earlier stages. ,there were fewer non-CKD speakers than CKD speakers,thus authors created new classification for speaker severity based on eGFR.Speakers with an eGFR of more than were considered non,CKD speakers participants,females, males ,whereas speakers with an eGFR of less than were considered CKD speakers.For CKD speakers,stage was defined as having an eGFR of or more and less than participants, females,males ,and stage as having an eGFR of or more and less than subjects,females,males. voices of CKD and non-CKD speakers were first compared and examined.On parameters that satisfied requirements for data normality, independent sample t-test was used,and Mann-Whitney test was used on parameters that did not.Second, voices of these three groupsthose without CKD, those in CKD stage ,and CKD stage 4were compared.On parameters that satisfied requirements for data normality,oneway ANOVA was used,and on parameters that did not, KruskalWallis test was used. Bonferroni post hoc test was additionally conducted.,correlation and regression analyses were conducted to examine relationship between eGFR and each parameter.All statistical analysis was performed using IBM SPSS Statistics..Speech-related features lists parameters that were chosen to represent different characteristics of speech in CKD speech analysis.With regard to impact of CKD on speech,authors utilized ' feature set and added new features,such as aerodynamic and glottal source parameters..Speech-related features.MFCCs representation of sound' short-term power spectrum used in sound processing is called Mel-frequency cepstrum MFC ,which is based on linear cosine transform of log power spectrum on nonlinear Mel scale of frequency.An MFC is made up of coefficients known as mel-frequency cepstral coefficients MFCCs. Applications for speaker identification and recognition have usually used MFCCs.Their applicability has been expanded to include speech quality evaluation for medical purposes.Using librosa toolkit,authors extract,dim MFCCs and log energy from each speech..Voice quality features Five voice quality features,jitter,shimmer,harmonic to noise ratio HNR ,number of voice breaks,and degree of voice breakswere chosen for this investigation.While shimmer,which is very similar to jitter,represents changes in amplitude,jitter represents changes in F0 over time. HNR is proportion of harmonic to noise energy.It has been demonstrated that jitter,shimmer,and HNR can be used to describe vocal traits and provide pathological voice diagnosis.Voice break features reveal vocal ability to maintain phonation.Using Praat ,all voice quality features are extracted. minimum and maximum pitches are respectively set to Hz and Hz for jitter,shimmer,and HNR. number of voice breaks is first feature in terms of voice breaking features. Praat divided pitch floor,which is set at Hz,by number of intervals between consecutive glottal pulses that are longer than. degree of voice breaks is then determined by dividing sum of voice break duration by speech duration..Prosody features Pitch,speech rate,and rhythm are three prosody feature categories that are extracted. Using Praat,authors calculate median,minimum,maximum, mean,and standard deviation of F0 for pitch. For speech rate,authors measure total duration,speech duration, speaking rate,articulation rate,pause duration,and number of pauses.Speaking rate is ratio of syllables generated to total duration,and articulation rate is ratio of syllables produced to speech duration.Authors include pause-related variables,such as number of pauses and pause duration,because CKD decreases respiratory function.Parselmouth is used to extract these features. Authors extract deltas,Varcos,rPVIs,and nPVIs for rhythm. proportion of vocalic utterance intervals is represented as. Consonantal and vocalic interval standard deviations are referred to as deltas,and normalized delta values by average length of these intervals are called Varcos. vocalic and consonantal intervals are ordered temporally in pairwise variability index PVI. raw PVI is referred to as rPVI and normalized PVI as nPVI.Correlatore.is used to extract these features from data..Phoneme-level pronunciation features Two categories of phoneme-level pronunciation features are percentage of correct phonemes and degree of vowel distortion. features of percentage of correct phonemes include percentage of correct consonants, percentage of correct vowels,and percentage of total correct phonemes PCT. speech recognizer that has been trained on speakers without CKD is used to extract these features. AI Hub corpus is used to train acoustic model,and Kaldi toolkit is used for ASR training. number of matches between phoneme sequence from an automatic speech recognition model and canonical pronunciation sequence is used to calculate PCC,PCV,and PCT. Vowel Space Area VSA ,Vowel Articulatory Index VAI , Formant Centralized Ratio FCR ,and F2-ratio are indicators of how distorted vowel is. region where first and second formant frequency coordinates F1,F2 of vowel are connected by line in two-dimensional space is called VSA. indicators of vowel centralization are VAI and FCR,and they have an antagonistic connection.They have been used to describe changes in vowel articulation as substitute parameters.High FCR and low VAI values are seen when vowel space is concentrated in relation to standard coordinates.By combining speech recognizer and Praat with ' methodology,these features are extracted..Aerodynamic feature objective measurement of effectiveness of respiratory mechanism during phonation is maximum phonation time MPT ,which is defined as capacity to maximally sustain vowel after having taken maximal inspiration.Praat is used to extract MPT..Glottal source parameters term glottal source refers to glottal flow,which is air evicted from lungs and modulated by vocal folds as it passes down mean sd med min max deltas,varcos, trachea.Authors suggest incorporating parameters relating to glottal flow because it is well known that CKD can affect respiration and that it can result in vocal cord edema.H1-H2,H1A1,H1-A2,and H1-A3 are four glottal source parameters that are used. first and second harmonics of Fourier spectrum are denoted by H1 and H2,respectively. amplitudes of first,second,and third formants are denoted by A1,A2, and A3,respectively.Those parameters are known as acoustic measurements to characterize differences along glottal constriction continuum. calculation of VoiceSauce , software that automatically extracts voice measurements from audio recordings,is used to extract glottal source features by Praat..Results statistically significant parameters are displayed in Tables, and. parameters measured in sustained vowel and sentence are referred to as and respectively.There were differences in voice quality,phoneme-level pronunciation,prosody, glottal source,and aerodynamic parameters when it was examined whether there was difference in voice according to existence and severity of disease by group comparison.In terms of voice quality, CKD groups showed lower jitter and shimmer values than non-CKD group,and lower value as severity of CKD group increased.Similarly, CKD groups showed higher values in HNR,and value increased with increasing severity. According to data,patients do not distort vowels at phoneme level,although both vowels and consonants are frequently mispronounced in patients.Patients specifically exhibit greater consonant errors than vowel errors. CKD groups showed higher pitch in males but lower pitch in females., CKD group showed longer speech duration and,as result,lower articulation rate. To understand impact of eGFR on each parameter,authors performed correlation and regression analysis.First,authors determine which parameter values rise or fall with eGFR by correlation analysis.There was significant correlation between eGFR and parameters in aerodynamic,glottal source,phoneme-level pronunciation,and prosody parameters,similar to findings of group comparisons.There was statistically significant positive correlation between eGFR and parameters,except Std F0 percent and deltaThen,using eGFR as an independent variable,authors performed regression analysis to see if eGFR has an impact on dependent variables.Similar to findings of correlation analysis, findings of regression analysis demonstrated that eGFR significantly affected aerodynamic,glottal source, phoneme-level pronunciation,and prosody parameters..Discussion Due to contradictory results of previous studies,as mentioned earlier,it was challenging to identify characteristics of CKD voice.,several metrics revealed different results from previous studies.Most previous studies reported larger values in CKD group for jitter and shimmer,however experimental results revealed lower values.In terms of fundamental frequency, regardless of gender,reported higher F0 and reported lower F0 in CKD groups., results of experiment revealed that while F0 was lower in CKD group for females,it was higher for males.It suggests that when examining CKD voice, gender should be considered..Non-CKD vs.CKD voice analysis It is interesting to observe that while there were no differences in sustained vowel between groups,there were differences in sentence utterance.This indicates need to investigate CKD patients' voices using range of utterances.There were differences between groups even in parameters that had not been examined in previous studies,such as phoneme-level pronunciation,speech speed,rhythm,and glottal source parameters.As result,employing various speech-related parameters,authors should examine different features of CKD speech..Non-CKD vs.CKD stage vs.CKD stage publications.Authors'll conduct classification experiment using range of deep learning and machine learning models to detect diseases and predict their severity. support vector machine SVM with those statistically significant parameters will be used initially. SVM classifier is most used classifier for automatically detecting voice disorders because it works better with small datasets and highdimensional data.Because corpus size is small in comparison to other classification tasks,such as image classification,authors will explore variety of deep learning models that excel on small-sized datasets,such as ResNet..CONCLUSION In this paper, speech corpus of CKD patients has been provided.It is tool for analyzing pathological voice analysis,automatically diagnosing diseases,and estimating disease severity.Totaling CKD speakers and non-CKD speakers,authors collected and analyzed their data. findings revealed that two groups significantly differed between voice quality,phoneme-level parameters. pronunciation,and prosody parameters were significantly correlated with eGFR,and eGFR substantially impacted those parameters. In this study,only findings for significant parameters were reported because purpose of this study is to introduce corpus authors developed and suggest means to use corpus.Authors will examine CKD patients' voices in greater depth in upcoming.ACKNOWLEDGEMENTS This research was supported by MSIT Ministry of Science and ICT ,Korea,under ITRC Information Technology Research Center support program IITP---- supervised by IITP Institute for Information Communications Technology Planning Evaluation..Correlation analysis between eGFR and parameters - - -.Regression analysis between eGFR and parameters - - - -.- - - - -.REFERENCES Webster.,Nagler.,Morton.,and Masson., Chronic kidney disease, lancet,vol.,no.,pp. -,Nov. Kwon.,and Han.,Diagnosis and screening of chronic kidney disease,Korean Journal of Medicine,vol., no.,pp. Hassan.,Effect of chronic renal failure on voice an acoustic and aerodynamic analysis, Egyptial Journal of Otolaryngology,vol.,no.,pp.-,Aug. Radish.Kumar and Jayashree.Bhat,Voice in Chronic Renal Failure,Journal of Voice,vol.,no.,pp.-, Nov. Abd El-gaber.,Sallan.,and El Sayed., Acoustic Characteristics of Voice in Patients with Chronic Kidney Disease,International Journal of General Medicine, vol.,pp.-,June. Jung.,Ryu.,Park.,Chung.,Ryu., and Kim.,Voice change in end-stage renal disease hoarseness and objective acoustic parameters,Journal of Voice,vol.,no.,pp.-,July. Zaky.,Mamdouh.,Esmat.,and Khalaf.,Voice problem in patient with chronic renal failure, Egyptian Journal of Otolaryngology,vol.,no.,pp.-,Nov. Mudawwar.,Alan.,Sarieddine.,Turfe., and Hamdan.,Effect of renal failure on voice,ENT Ear,Nose Throat Journal,vol.,no.,pp.-,Jan Ahn. H1,H2 Measure.Speech Sciences, Lee.,Kim.,Sim.,Nam.,Choi.,and Park.,Auditory-perceptual evaluation of speech of adults with hearing impairment based on suprasegmental factors,speech intelligibility,and speech acceptability, Communication Sciences Disorders,vol.,no.,pp. -,Nov. IBM Corp.Released.IBM SPSS Statistics for Windows, Version.Armonk,NY IBM Corp Yeo.,Kin.,and Chung.,Automatic Severity Classification of Korean Dysarthric Speech Using Phoneme, Level Pronunciation Features,in Proc.Interspeech, pp.-, Benba.,Jilbab.,Hammouch.,and Sandabad., Voiceprints analysis using MFCC and SVM for detecting patients with Parkinsons disease,in International conference on electrical and information technologies ICEIT, pp..McFee.Raffel.Liang.Ellis.McVicar. Battenberg,and.Nieto,librosa Audio and music signal analysis in python,in Proceedings of 14th python in science conference,vol.,pp.-,July. Teixeira.,Oliveira.,and Lopes.,Vocal acoustic analysis-jitter,shimmer and hnr parameters,Procedia Technology,vol.,pp.-,Dec..Boersma,Praat, system for doing phonetics by computer, Glot International,vol.,no.,pp. Hernandez.,Yeo.,Kim.,Chung., September.Dysarthria Detection and Severity Assessment Using Rhythm-Based Metrics.In INTERSPEECH pp..,Jadoul.Thompson.de Boer,Introducing Parselmouth Python interface to Praat,Journal of. Hernandez.,Kim.,Chung.Prosody-based measures for automatic severity assessment of dysarthric speech. Applied Sciences..Mairano,and.Romano,Un confronto tra diverse metriche ritmiche usando Correlatore,In Schmid., Schwarzenbach.Studer.eds.La dimensione temporale del parlato,Proc.of National AISV Congress, University of Zurich,Collegiengebaude,- February , Torriana,pp. AIHub Homepage.Povey.Ghoshal.Boulianne.Burget.Glembek Goel,and.Vesely, Kaldi speech recognition toolkit,In IEEE workshop on automatic speech recognition and understanding. Sandoval.,Berisha.,Utianski.,Liss.,and Spanias.,Automatic assessment of vowel space area, Journal of Acoustical Society of America,vol.,no., pp.EL477-EL483,Nov. Skodda.,Visser.,and Schlegel.,Vowel articulation in Parkinsons disease,Journal of voice,vol.,no.,pp. -,July. Kim.,Kim.,Ko.,Kim.,Kim.,and Ko.,Characteristics of vowel space and speech intelligibility in patients with spastic dysarthria,Communication Sciences Disorders,vol.,no.,pp.,,Sep. Speyer.,Bogaardt.,Passos.,Roodenburg., Zumach.,Heijnen.,Baihens.,Fleskens., and Brunings.,Maximum phonation time variability and reliability,Journal of Voice,vol.,no.,pp.-, Oct. Drugman.,Dubuisson.,and Dutoit.,On mutual information between source and filter contributions for voice. Online.\\n\\nKumar.,Bhat.,and Mukhi.,Vowel harmonic amplitude differences in persons with vocal nodules,Journal of Voice,vol.,no.,pp. Lee.,Cho.,Song.,Lee.,Kim.,and Kim., Aging effect on Korean female voice Acoustic and perceptual Logopaedica,vol.,no.,pp. Keating.,and Esposito.,Linguistic Voice Quality, UCLA Working Papers in Phonetics.Online. paper.pdf Shue,Yen-Liang, Voice Source in Speech Production Data,Analysis and Models,Ph.dissertation,Dept.Elect. Eng.,Univ.California,Los Angeles. Hedge.,Shetty.,Rai.,and Dodderi., survey on machine learning approaches for automatic detection of voice disorders,Journal of Voice,vol.,no.,pp.e11 e33,July. He.,Zhang.,Ren.,Sun.Deep residual learning for image recognition.In Proceedings of IEEE conference on computer vision and pattern recognition pp.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2304.04280v1.FrenchMedMCQA__A_French_Multiple_Choice_Question_Answering_Dataset_for___Medical_domain', embedding=None, metadata={'license': 'publicdomain'}, excluded_embed_metadata_keys=['license'], excluded_llm_metadata_keys=['license'], relationships={}, hash='e53752703e7c0710da23f44b215e9db02da02bbb6994c2a8d2f2e9dd089588c8', text='FrenchMedMCQA French Multiple-Choice Question Answering CHU de Nantes,La clinique des donnes,Nantes University3 first publicly available Multiple-Choice Question Answering MCQA dataset in French for medical domain.It is composed of ,questions taken from real exams of French medical specialization diploma in pharmacy,mixing single and multiple answers.Each instance of dataset contains an identifier, question, five possible answers and their manual correction.Authors propose first baseline models to automatically process this MCQA task in order to report on current performances and to highlight difficulty of task.detailed analysis of results showed that it is necessary to have representations adapted to though FrenchMedMCQA is in French.Corpus,models and tools are available online.\\nnatural language processing NLP task that consists in correctly answering set of questions by selecting one or more of given candidates answers called options while minimizing number of errors.MCQA is one of most difficult NLP tasks because it requires more advanced reading comprehension skills and external sources of knowledge to reach decent performance.\\nIn MCQA,authors can distinguish two types of answers single and multiple ones.Most datasets focus on single answer questions,such as MCTest Richardson et al.,ARCchallenge Clark et al.,OpenBookQA Mihaylov et al.,QASC Khot et al., Social-IQA Sap et al.,or RACE Lai et al. To our knowledge,few studies have been done to construct medical MCQA dataset.Authors can cite MedMCQA Pal et al.,and HEADQA Vilares and Gmez-Rodrguez,corpora which contain single answer questions in Spanish and English respectively.For multiple answer questions,MLEC-QA Li et al.,provides 136k questions in Chinese covering various biomedical sub-fields,such as clinic,public health and traditional Chinese medicine.\\nFrench community has recently greatly increased its efforts to collect and distribute medical corpora.Even if no open language model is currently available,authors can cite named entity recognition Nvol et al.,and information extraction Grabar et al.,tasks., they remain relatively classic,current approaches already reaching high level of performance.\\nfirst publicly available MCQA corpus in French related to medical field,and more in pharmacological domain.This dataset contains questions taken from real exams of French diploma in pharmacy.Among difficulties related to task, questions asked may require single answer for some and multiple ones for others.\\nAuthors propose to evaluate state-of--art MCQA approaches,including an original evaluation of several word representations across languages.\\nMain contributions of paper concern distribution of an original MCQA dataset in French related to medical field, state-of--art approach on this task and first analysis of results,and an open corpus,including tools and models,all available online.\\ndataset and discuss data collection and distribution.\\nquestions and their associated candidate answer were collected from real French pharmacy\\n\\nexams on remede1 website.This site was built around community linked to medical field medicine,pharmacy,odontology.,offering multiple information news,job offers,forums.both for students and professionals in these sectors of activity.Questions and answers were manually created by medical experts and used during examinations. dataset is composed of , single one,for total of ,questions.Each instance of dataset contains an identifier, question,five options labeled from to and correct answer. average question length is.tokens and average answer length is.tokens.\\nvocabulary size is of 13k words,of which.8k are estimated medical domain-specific words.\\nrelated to medical field.Authors find an average of.medical domain-specific words in each question of words in average of question and.in each answer of words in average of an answer.On average, targeted medical domainspecific word is present in questions and in answers.\\ndataset distribution for train,development dev and test sets detailed per number of answers.\\nnumber of correct responses per question.Globally,of questions are kept for train, for validation and last for testing.\\nAnswers FrenchMedMCQA dataset distribution.\\nuse alone of question to automatically find right answer is not sufficient in context of MCQA task.State-of--art approaches then require external knowledge to improve system performances Izacard and Grave,Khashabi et al.In our case,authors decide to build two-step retriever-reader architecture comparable pharmacie qcm-internat.html to UnifiedQA Khashabi et al.,where retriever job is to extract knowledge from an external corpus and using it by reader to predict correct answers for each question.presents two-step general pipeline,first step being retriever module,that extracts external context from question see Section.,and second step being reader,called here question-answering module see Section.,that automatically selects answer to targeted question.\\nSteps of pipeline.\\nAn external medical-related corpus fully composed of French has first been collected from two online sources Wikipedia life science and HAL, latter being an open archive run by French National Centre for Scientific Research CNRS where authors can deposit scholarly documents from all academic fields.In our case,authors focus on extracting papers and thesis from various specialization,such as Human health and pathology,Cancerology,Public health and epidemiology,Immunology,Pharmaceutical sciences,Psychiatric disorders and Drugs.\\nThis results in million of passages.portion of text that contains at least characters in HAL and 286k passages in Wikipedia.\\nThis corpus is then used as context extension for question.Authors therefore used retriever pipeline to automatically assign questions to most likely passage in external source.Two retrieval approaches are compared in this article BM25 Okapi Trotman et al.,for implementation of base BM25 algorithm Robertson and Sparck Jones.\\nand Gurevych,is used to perform semantic search using state-of--art language Transformers library Wolf et al.\\nFor both approaches, goal is to embed each passage of external corpus into vector space using one of two representations.On its side, question is concatenated with five options.answers associated to question to form new query embedded in same vector space.\\nEmbeddings from question and passages are finally compared to return closest passages of query here, cosine similarity is distance metric.For approach,authors used fast and non domain specific model called MiniLMv2 Wang et al.Note that 1best passage is only used in these experiments.\\ngoal of our experiments was to compare baseline approaches regarding two different paradigms. first one is referred to discriminative approach and consists in assigning one of classes to input based on their projection in multidimensional space.Authors referred to it as multi-class task.\\nAt opposite, second method is generative one which consists of generating sequence of tokens, called free text,based on sequence of input tokens identical to one used for discriminative approach. difference with discriminative approach lies in fact that authors are not outputting single class,like ABE for question ,but sequence of tokens following rules of natural language and referring to combination of classes like in case of our studied generative model see Section.\\nFour discriminative representations are studied in this paper.\\nAuthors firstly propose to use CamemBERT Martin et al., generic French pretrained language model based on RoBERTa Liu et al.Since no language representation adapted to medical domain are publicly available for French,authors propose to evaluate two pre-trained representations BioBERT Lee et al., and PubMedBERT Gu et al.,both trained on English medical data and reaching SOTA results on biomedical NLP tasks,including QA Pal et al.,authors consider multilingual generic pre-trained model,XLM-RoBERTa Conneau et al.,based on RoBERTa,to evaluate gap in terms of performance with CamemBERT.\\ntheir interest on several NLP tasks,in particular for text generation and comprehension tasks.Among these approaches,BART Lewis et al.,is denoising autoencoder built with sequence-tosequence model.Due to its bidirectional encoder and left-to-right decoder,it can be considered as generalizing BERT and GPT Radford et al., respectively.BART training has two stages noising function used to corrupt input text, and sequence-to-sequence model learned to reconstruct original input text.Authors then propose to evaluate this representation in this paper.\\nEach studied discriminative and generative model is fine-tuned on MCQA task with FrenchMedMCQA training data using an input sequence composed of question,its associated options.possible answers and its additional context,all separated with SEP token.CLS question SEP answer.SEP answer.SEP answer.SEP answer.SEP answer.SEP context EOS.\\nFor each question, context is text passage with highest confidence rate and can either be obtained using BM25 algorithm or semantic search as described in Section.\\nConcerning outputs of systems,authors have for BART generative model plain text containing letter of answers from to separated with plus signs in case of questions with multiple answers.For other architectures.discriminative approaches ,authors simplify multi-label problem into multi-class one by classifying inputs into one of existing combinations in corpus.Here, class may be combination of multiple labels.if correct answers are and ones,then authors consider correct class being AB,which explains number of classes.\\nmajority of tasks concentrate either on multiclass or binary classification since they have single class at time.,occasionally,authors will Wiki Wiki MiniLMv2 HAL MiniLMv2 BioBERT V1.\\nPerformance in on test set using Hamming score and EMR metrics.\\nhave task where each observation has many labels.In this case,authors would have different metrics to evaluate system itself because multi-label prediction has an additional notion of being partially correct.Here,authors focused on two metrics called Hamming score commonly multilabel accuracy and Exact Match Ratio EMR.\\naccuracy for each instance is defined as proportion of predicted correct labels to total number predicted and actual of labels for that instance. accuracy is average across all instances.It is less ambiguously referred to as Hamming score rather than Multi-label Accuracy.\\nof predictions matching exactly ground truth answers.To be computed,authors sum number of fully correct questions divided by total number of questions available in set.question is considered fully correct when predictions are exactly equal to ground truth answers for question.all multiple answers should be correct to count as correct question.\\nHamming score and EMR of all studied architectures and retrievers pipelines.For sake of comparison, column Without Context has been added,considering that no retriever is used.no external passage is present in QA system.\\ndifferent according to used metric.BioBERT V1.reaches best performance using Hamming score and BART-base in case of EMR.\\nThese first observations are quite surprising since both models are trained on English data.While authors could expect higher performance with French these models are trained on specialized data for BART finally shows that language models trained on generic data are inefficient for MCQA task on medical domain.\\nIn all considered architectures,context seems to have small impact on systems performance,with limited increase or drop depending on configurations.Clearly, RoBERTa performance is much higher without context.without use of retriever part ,while models based on own baseline performances with external context.\\nfact that authors consider ,best passage only may explain this impact.\\nConcerning XLM-RoBERTa-base cross lingual representation ,authors obtain in case of context extracted using BM25 from Wikipedia, worst Hamming score and EMR out of all discriminative approaches.This confirms our first observation that non-specialized model does not allow to achieve best performance on this task.\\nUsing BM25 promotes better context than semantic search using MiniLMv2 on both Wikipedia and HAL for most of runs., source depends of retriever and model used.majority of experiments demonstrate that HAL outperforms Wikipedia on BM25 despite fact that best model was obtained using Wikipedia.\\nscripts to replicate experiments2 as well as pre-trained models3 are available online.\\noriginal,open and publicly available MultipleChoice Question Answering MCQA dataset in medical field.This is first French corpus in this domain,including single and multiple answers to questions.Several state- art systems have been evaluated to show current performance on dataset. analysis of these first results notably highlighted fact that language models specialized to medical domain allow us to reach better performance than generic models,even if these have been trained in different language here,English biomedical models applied to French.\\nexisting methods for task of MCQA,considering other strategies for retriever module multiple passages,combining contexts.Likewise,authors will consider construction of data representation models for French specialized for medical domain.\\nThis work was financially supported by Zenidoc, DIETS project financed by Agence Nationale de la Recherche ANR under contract ANR--CE23,and ANR AIBy4 ANR20-THIA.This work was performed using HPC resources from GENCI-IDRIS Grant 2022AD011013061R1 and,AD011013715.\\nPeter Clark,Isaac Cowhey,Oren Etzioni,Tushar Khot, Ashish Sabharwal,Carissa Schoenick,and Oyvind Tafjord.Think you have solved question answering try arc, ai2 reasoning challenge.ArXiv,\\n\\nAlexis Conneau,Kartikay Khandelwal,Naman Goyal, Vishrav Chaudhary,Guillaume Wenzek,Francisco Guzmn,Edouard Grave,Myle Ott,Luke Zettlemoyer,and Veselin Stoyanov.Unsupervised cross-lingual representation learning at scale.\\nProceedings of 58th Annual Meeting of Association for Computational Linguistics,pages ,Online.Association for Computational Linguistics.\\nNatalia Grabar,Vincent Claveau,and Clment Dalloux.\\nCAS French corpus with clinical cases.In Proceedings of Ninth International Workshop on Health Text Mining and Information Analysis,pages ,Brussels,Belgium.Association for Computational Linguistics.\\nJianfeng Gao,and Hoifung Poon.\\nDomainspecific language model pretraining for biomedical natural language processing.ACM Transactions on Computing for Healthcare.\\nGautier Izacard and Edouard Grave.\\nLeveraging passage retrieval with generative models for open domain question answering.\\n\\nDaniel Khashabi,Sewon Min,Tushar Khot,Ashish Sabharwal,Oyvind Tafjord,Peter Clark,and Hannaneh Hajishirzi.Unifiedqa Crossing format boundaries with single qa system.\\nTushar Khot,Peter Clark,Michal Guerquin,Peter Jansen,and Ashish Sabharwal.\\ndataset for question answering via sentence composition.\\nGuokun Lai,Qizhe Xie,Hanxiao Liu,Yiming Yang, and Eduard Hovy.RACE Large-scale ReAding comprehension dataset from examinations.In ,Copenhagen,Denmark.Association for Computational Linguistics.\\nand Jaewoo Kang.BioBERT pre-trained biomedical text mining.Bioinformatics.\\nMarjan Ghazvininejad,Abdelrahman Mohamed,Omer Levy,Ves Stoyanov,and Luke Zettlemoyer.\\nBart Denoising sequence-to-sequence pre-training for natural language generation,translation,and comprehension.\\nJing Li,Shangping Zhong,and Kaizhi Chen.\\nQuestion Answering Dataset.In Proceedings of Punta Cana,Dominican Republic.Association for Computational Linguistics.\\nYinhan Liu,Myle Ott,Naman Goyal,Jingfei Du,Mandar Joshi,Danqi Chen,Omer Levy,Mike Lewis, Luke Zettlemoyer,and Veselin Stoyanov.\\nRoberta robustly optimized bert pretraining approach.\\nLouis Martin,Benjamin Muller,Pedro Javier Ortiz Surez,Yoann Dupont,Laurent Romary,ric de la Clergerie,Djam Seddah,and Benot Sagot.\\nCamemBERT tasty French language model.\\nIn Proceedings of 58th Annual Meeting of Association for Computational Linguistics,pages ,Online.Association for Computational Linguistics.\\nTodor Mihaylov,Peter Clark,Tushar Khot,and Ashish Sabharwal.Can suit of armor conduct electricity new dataset for open book question answering.In EMNLP.\\nAurlie Nvol,Cyril Grouin,Jeremy Leixa,Sophie Rosset,and Pierre Zweigenbaum. medical entity recognition and normalization.\\nProc of BioTextMining Work,pages.\\nAnkit Pal,Logesh Kumar Umapathi,and Malaikannan Sankarasubbu.Medmcqa large-scale multi-subject multi-choice dataset for medical domain question answering.\\nConference on Health,Inference,and Learning,volume of Proceedings of Machine Learning Research,pages.PMLR.\\nAlec Radford,Jeff Wu,Rewon Child,David Luan, Dario Amodei,and Ilya Sutskever.Language models are unsupervised multitask learners.\\nNils Reimers and Iryna Gurevych.\\nSentence embeddings using siamese bertnetworks.\\nMatthew Richardson,Christopher.Burges,and Erin Renshaw.MCTest challenge dataset for open-domain machine comprehension of text.\\nIn Proceedings of Conference on Empirical Methods in Natural Language Processing,pages ,Seattle,Washington,USA.Association for Computational Linguistics.\\nStephen.Robertson and Karen Sparck Jones.\\nRelevance Weighting of Search Terms,page.Taylor Graham Publishing,GBR.\\nMaarten Sap,Hannah Rashkin,Derek Chen,Ronan LeBras,and Yejin Choi.Socialiqa Commonsense reasoning about social interactions.\\nAndrew Trotman,Antti Puurula,and Blake Burgess.\\nImprovements to bm25 and language models examined.In Proceedings of Australasian ,New York,NY,USA.Association for Computing Machinery.\\nDavid Vilares and Carlos Gmez-Rodrguez.\\nHEAD-QA healthcare dataset for complex reasoning.\\nIn Proceedings of 57th Annual Meeting of Association for Computational Linguistics,pages ,Florence,Italy.Association for Computational Linguistics.\\nWenhui Wang,Hangbo Bao,Shaohan Huang,Li Dong, and Furu Wei.\\nMinilmv2 Multi-head selfattention relation distillation for compressing pretrained transformers.\\nThomas Wolf,Lysandre Debut,Victor Sanh,Julien Chaumond,Clement Delangue,Anthony Moi,Pierric Cistac,Tim Rault,Rmi Louf,Morgan Funtowicz,Joe Davison,Sam Shleifer,Patrick von Platen, Clara Ma,Yacine Jernite,Julien Plu,Canwen Xu, Quentin Lhoest,and Alexander.Rush.\\nHuggingfaces transformers State-of--art natural language processing.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2305.06801v1.Detecting_Idiomatic_Multiword_Expressions_in_Clinical_Terminology_using___Definition_Based_Representation_Learning', embedding=None, metadata={'license': 'publicdomain'}, excluded_embed_metadata_keys=['license'], excluded_llm_metadata_keys=['license'], relationships={}, hash='370bed4949e1a9b42f3204c8b86a9a50af7c34a16ea32a6fbbfc3108eb1a32f2', text='Detecting Idiomatic Multiword Expressions in Clinical Terminology using Definition-Based Representation Learning definition-based semantic models for detecting idiomatic and semi-idiomatic multiword expressions MWEs in clinical terminology.\\nstudy focuses on biomedical entities defined in UMLS ontology and aims to help prioritize translation efforts of these entities.\\ntool for scoring idiomaticity of biomedical MWEs based on degree of similarity MWEs and weighted average of representation of their constituents.Authors achieve this names and their definitions,called BioLORD.\\nimportance of this definition-based approach is highlighted by comparing BioLORD model to two other state-of--art biomedical language models based on Transformer SapBERT and CODER. results ability to identify idiomatic MWEs,not replicated in other models.\\ncorpus-free idiomaticity estimation helps ontology translators to focus on more challenging MWEs.\\nTranslation in biomedical domain remains challenging due to large number of specific and ad-hoc usage of terminology Neves et al.Some medical ontologies such million entities.Out of these,only fraction has already been labelled in languages other than English.While large efforts to translate some medical ontologies such as SnomedCT Schulz and Klein, can be noted,few if any of these efforts have yet to yield full coverage of ontology in their target language Macary,Auwers.\\nprioritization of expert translation of some entity names over others,as translating popular entities makes ontology usable to large number of practitioners at lower cost.But,with rise of automatic translation tools,another factor worth considering in prioritization is translation difficulty of entities being passed on to medical translation experts.Their efforts should indeed better be directed to cases where automatic translation does not provide good results.\\nIn this context,idiomaticity has key role to play.\\nIndeed, automatic translation of idiomatic1 MWEs poses significant challenge,as juxtaposing translation of each individual constituent often results in loss of meaning that can,in some cases,be catastrophic.This difficulty has been noted by prominent researchers such as Koehn and Knowles and Evjen.As result, identifying such idiomatic MWEs would therefore immensely benefit prioritization of translation efforts of medical ontologies.\\nhave been presented in past Ramisch et al., Kafando et al.,Zeng and Bhat, authors found that applying them to medical domain and especially its clinical counterpart was challenging due to extreme corpus size that would be required to produce statistically significant results for long tail of medical entities.\\nIn this paper,authors investigate another approach relying on an ontological representation learning strategy based on definitions,and empirical properties of semantic latent spaces,described by Nandakumar et aland Garcia et al.\\nIn particular,authors investigate whether semantic models trained from ontological definitions perform better than other semantic models for task of identifying idiomatic MWEs without relying on their usage in context,using novel self-explainability score which will be introduced in Section.\\n1MWEs are referred to as idiomatic if their meaning cannot be deduced from interpretation of their constituents,in line with definition of Multiword Terms presented by Ramisch et al.examples in biomedical domain include Gray Matter or Morning Sickness.\\n\\nIn this paper,authors use cosine similarity metric to compare representation of MWE with weighted average of representations of its two constituents,after embedding each of these with same semantic model which is based on Transformer pipeline.Any difference in representation between these must come from interactions between constituents within Transformer when these constituents are combined in MWE.\\nAfter collecting multiword entity names, chosen semantic model is used to map obtained MWEs W1.Wn to their latent representations,either as whole or word-per-word Ri.\\nSemReprOf W1.Wn Ri SemReprOf Wi semantic model,being based on Transformer Mean Pooling pipeline see , produces its representations by averaging representation of tokens it is provided as an input after taking their interactions into account SemReprOf Wi W1.Wn To isolate effect of these interactions,authors representations of constituents of MWE with weights as generalization of above iRi corresponds to degree of similarity between their latent semantic representation and best2 weighted average of independent representations of their constituents iRi.\\nmax Only strong inter-constituent interactions should be able to explain low self-explainability scores.\\n2We determine optimal weights in Appendix.\\nBased on this insight,authors hypothesize that low self-explainability scores identify MWEs that semantic model treats as idiomatic.To validate our hypothesis,authors will demonstrate that there is indeed statistically significant difference in selfexplainability scores between idiomatic and nonidiomatic MWEs,among chosen population.\\nFor our analysis,authors construct set of two-words subsequently divided into two groups by our annotators4 those which were perceived as idiomatic or semi-idiomatic and those which were perceived as self-explanatory.\\nAuthors hypothesize that definition-based pretraining is essential for this analysis to produce good results.,as proposed analysis could be applied to any contextual text representation model,authors set out to evaluate benefits of definition-based pretraining of BioLORD model Remy et al.,by comparing its results with two strong alternatives SapBERT Liu et al., and CODER Yuan et al.These two state-of--art biomedical language models were trained using contrastive learning and UMLS, but not using definitions as semantic anchor.\\n3All two-words entity names from UMLS were included, after filtering out pairs containing words which are either too frequent occurences or too rare occurences in UMLS ontology.This amounts to about thousand two-words MWEs.to be precise.\\n4The labelling was performed by two annotators trained linguist specialized in MWEs who is currently following course on medical translation,and NLP practitioner with multiple years of experience in clinical NLP with an interannotator agreement of and kappa score of.\\nDensity of self-explainability scores produced by BioLORD for all MWEs of our dataset.\\nDensity of self-explainability scores produced by BioLORD for idiomatic MWEs.\\nProportion of MWEs preceived as idiomatic, in function of self-explainability score produced by BioLORD bullets represent our annotations.\\nComparison between ROC curves of various biomedical models,which shows that BioLORD has much large area under curve than other models. green dot represents 95th percentile operating point described in paper this is point where about half of idiomatic MWEs are recalled achieving same result with other models orange and red dots or through chance black dot requires processing multiple times more MWEs than BioLORD.\\nAuthors start our analysis by plotting empirical distribution of self-explainability scores for all considered UMLS entities.Authors report this empirical distribution as histogram in.\\nwhich seems to give weight to hypothesis that MWEs exist on spectrum of idiomaticity,as described by Cowie ,and do not form clearly distinct idiomaticity classes.\\nBased on our annotations,authors evaluate proportion of idiomatic MWEs present in subset of bins of self-explainability scores see.\\nThis enables us to estimate full distribution with population counts see.\\nmeans.vs.,indicating that our selfexplainability score is indeed significantly lower for idiomatic MWEs than for non-idiomatic ones.\\nabout.of MWEs in our dataset appeared idiomatic or semi-idiomatic in nature.To evaluate how effectively our self-explainability score can help identifying idiomatic MWEs,authors determined threshold score enabling recall of about of idiomatic MWEs in our dataset.This corresponds to about MWEs featuring similarity below.,consisting of outliers at or below percentile of our self-explainability scores.\\nTo confirm this,authors annotated more extensively MWEs of our dataset falling into these outlier percentiles.Authors find that about of these MWEs appear idiomatic to our annotators,which is in line with our population-based estimates of.of idiomatic MWEs recall. of idiomatic MWEs out of these of outliers, yielding an expected precision of.\\nOf course, threshold of.represents only one of possible operating points of our model.\\nBy varying this threshold,authors compute receiver operating characteristic ROC of our classifier,and plot it in green curve.Authors find that our model shows an area under curve AUC of.\\nof BioLORDs definition-based training.Indeed, curve fail to provide classifier that is as effective as BioLORD for this task,with AUC scores of.\\nand.respectively.See .\\nresults,authors report MWEs featuring lowest self-explainability scores,for each of considered models see.Based on this,authors note that outliers of BioLORD model are not only of higher quality,but feature significantly lower self-explainability scores.\\nAuthors interpret this as an indication that,to produce definition-grounded representations for MWEs, BioLORD model has to devote more of its weights to memorize and specialize idiomatic MWEs than other models.\\nAuthors can further this impression by looking at.While SapBERT has distribution of scores similar to BioLORD, difference between idiomatic and self-explanatory MWEs is less pronounced,leading to more mixups.Looking further, feature almost no score variation between MWEs in general,and appears to treat few MWEs as idiomatic besides few general-purpose hold-outs from its original pre-training.These findings again comfort idea that definition-based pre-training is important to achieve good results.\\nDensity of self-explainability scores produced by compared models for idiomatic solid and self-explainable dotted MWEs of our dataset.\\nMost extreme self-explainability outliers for models compared in this study.An extended version of this table can be found in Appendix.\\nIn this paper,authors investigated suitability of definition-based semantic models for detecting idiomatic MWEs in terminology of domain.Authors were able to demonstrate that our proposed selfexplainability score can indeed serves as proxy for idiomaticity,and observed that BioLORD model indeed displays strong ability to perform this evaluation in biomedical domain.\\ncorpus-free idiomaticity estimation thereby translators to focus on more challenging MWEs, with about half of idiomatic MWEs contained in of self-explainability score outliers.\\n,authors were able to show that biomedical models which were not trained using definition-based strategy perform significantly showing importance of definition-based pretraining strategy in development of reliable semantic representations for idiomatic MWEs.\\nIt is worth noting that approach described in this paper can only be expected to operate reliably on entities which can be accurately represented in latent space by chosen semantic model either through its exposure to textual definitions or ontological relationships about entity during pre-training,or through its generalization abilities.\\nUnlike past approaches for detecting idiomatic to recognize idiomatic MWEs from their usage in corpus.It would be an interesting future work to investigate how to combine examples of uses and ontological knowledge to develop better incontext idiomaticity evaluation for MWEs.\\nAn additional limitation of our work,is that authors limited our analysis to UMLS entities consisting of exactly two words.This is not limitation of our proposed approach per se,but authors acknowledge that further work should probably be carried out to investigate how to best handle longer sequences.\\nauthors of this paper do not report any particular ethical concern regarding its content.\\nTom Auwers.Snomed ct translated into dutch and french by belgian national release centre.\\nOlivier Bodenreider.\\nlanguage system UMLS integrating biomedical terminology.\\nissue D26770.\\n\\nCowie. Treatment of Collocations and Idioms in Learners Dictionaries.Applied Linguistics,II.\\nJohn Mervyn Evjen.Highlighting difficulties in idiomatic translation.Spectrum.\\nMarcos Garcia,Tiago Kramer Vieira,Carolina Scarton, Marco Idiart,and Aline Villavicencio.Probing for idiomaticity in vector space models.In Proceedings of 16th Conference of European Chapter of Association for Computational Linguistics Main Volume,pages ,Online.\\nAssociation for Computational Linguistics.\\nRodrique Kafando,Rmy Decoupes,Sarah Valentin, Lucile Sautot,Maguelonne Teisseire,and Mathieu Roche.ITEXT-BIO Intelligent term EXTraction for BIOmedical analysis.Health Inf.Sci.Syst.\\nPhilipp Koehn and Rebecca Knowles.Six challenges for neural machine translation.In Proceedings of First Workshop on Neural Machine Translation,pages ,Vancouver.Association for Computational Linguistics.\\nFangyu Liu,Ehsan Shareghi,Zaiqiao Meng,Marco Basaldella,and Nigel Collier.Self-alignment pretraining for biomedical entity representations.In American Chapter of Association for Computational Linguistics Human Language Technologies, pages ,Online.Association for Computational Linguistics.\\nFrancois Macary.An exemplar of collaboration first release of snomed ct common french translation.\\nNavnita Nandakumar,Timothy Baldwin,and Bahar Salehi.How well do embedding models capture non-compositionality view from multiword expressions.In Proceedings of 3rd Workshop on Evaluating Vector Space Representations for NLP, pages ,Minneapolis,USA.Association for Computational Linguistics.\\nNvol,Cristian Grozea,Amy Siu,Madeleine Kittner,and Karin Verspoor.\\nWMT biomedical translation shared task Evaluation on Medline test sets.In Proceedings of Third Conference on Machine Translation Shared Task Papers,pages ,Belgium,Brussels.Association for Computational Linguistics.\\nGiorgio Maria Di Nunzio,Federica Vezzani,Christel Gerardin,Rachel Bawden,Darryl Johan Estrada, Salvador Lima-lopez,Eulalia Farre-maduel,Martin Krallinger,Cristian Grozea,and Aurelie Neveol.\\nFindings of WMT biomedical translation shared task Monolingual clinical case reports.In Proceedings of Seventh Conference on Dhabi,United Arab Emirates Hybrid.Association for Computational Linguistics.\\nCarlos Ramisch,Aline Villavicencio,and Christian Boitet.\\nmwetoolkit framework for multiword expression identification.\\nof Seventh International Conference on Language Resources and Evaluation LREC10 ,Valletta,Malta.European Language Resources Association ELRA.\\nFranois Remy,Kris Demuynck,and Thomas Demeester.\\nrepresentations from definitions for biomedical concepts and their textual descriptions.\\nIn Findings of Association for Computational Linguistics EMNLP ,pages ,Abu Dhabi, United Arab Emirates.Association for Computational Linguistics.\\nStefan Schulz and Gunnar.Klein.\\nct advances in concept mapping,retrieval,and ontological foundations.selected contributions to .\\nMaking,S1.\\nZheng Yuan,Zhengyun Zhao,Haixia Sun,Jiao Li,Fei Wang,and Sheng Yu.\\nCoder Knowledgeinfused cross-lingual medical term embedding for term normalization.\\nJournal of Biomedical Informatics.\\nZiheng Zeng and Suma Bhat.\\nIdiomatic expression identification using semantic compatibility.\\nTransactions of Association for Computational Linguistics.\\nIn this appendix,authors derive analytical solution for problem of finding optimal weighted average of representation of constituents of MWE given task of maximizing cosine similarity between their weighted average and representation of MWE itself.\\nLet R1 and R2 be two vectors representation model.Let be vector representation of MWE through BioLORD model.\\nsee.\\nobjective is to maximize cosine similarity between and weighted average of vectors Ri with weights.Because cosine similarity between two vectors does not depend on their respective lengths,authors can without loss of generality try to maximize following expression for mixing parameter.\\nCosSim R1 R2, R1 R2 R1 R2. Because maximum cosine similarity will necessarily be positive,authors can look for maximum of its square instead.Authors will find our optimum by looking at points where derivative is equal CosSim2 R1 R2 recalling.\\n\\ncomputing inner derivatives.\\n\\ndividing both sides by and R1 R2.\\n\\nRepresentation of problem scalar products Rxy Rx Ry.Given authors are trying to find scaling coefficients for Ri vectors, authors can first normalize them to make their norm is equal to one,without loss of generality,such that R11 R22.\\nexpanding products.\\nR11 2R12 2R22 R2 R1R12 R2R12 R1R22 2R2R22.isolating on left side.\\nR12R2 R1R22 R1R12 R11R2.giving us formula of.\\n\\ngiving us formula of.\\nR1 R12R2 R2 R21R1 Intuition If authors assume that constituents of entity have orthogonal meanings R1 R2 , this gives R1 and R2 which are cosine similarities of each constituent with respect to entire MWE.\\nExamples of similarity outliers for considered models.Self-explainability outliers for BioLORD.Self-explainability outliers for SapBERT.Self-explainability outliers for CODER This work would not have been possible without joint financial support of Vlaams Agentschap Innoveren Ondernemen VLAIO and RADar innovation center of AZ Delta hospital group.\\njoint session to which this paper was submitted, which enabled blooming of this collaboration between machine learning engineers and linguists thanks to its existence.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2306.00665v1.Automatic_Glossary_of_Clinical_Terminology__a_Large_Scale_Dictionary_of___Biomedical_Definitions_Generated_from_Ontological_Knowledge', embedding=None, metadata={'license': 'publicdomain'}, excluded_embed_metadata_keys=['license'], excluded_llm_metadata_keys=['license'], relationships={}, hash='271daa52d4f20083c5694eb304ce97d47cd1192484798fc35432a5902eb0a7bd', text=\"Automatic Glossary of Clinical Terminology Large-Scale Dictionary of Biomedical Definitions Generated from Ontological Knowledge IDLab Internet and Data Science Lab ,Ghent University imec , comprehensive biomedical ontology.\\nreadily interpretable by non-experts,or patients looking at their own electronic health records EHR.Clear definitions or descriptions in understandable language are often not available.\\nTherefore,generating human-readable definitions for biomedical concepts might help make and understandable to wider public.\\nAGCT , large-scale biomedical dictionary of clinical concepts generated using high-quality knowledge contained in SnomedCT.\\n\\n,using high-quality verbalization of concept.significant subset of generated definitions was subsequently judged by NLP researchers with biomedical expertise on,point scales along following three axes factuality, insight,and fluency.\\nResults AGCT contains ,computergenerated definitions for SnomedCT concepts, covering various domains such as diseases,procedures,drugs,and anatomy.\\nlength of definitions is words. definitions were assigned average scores of over.\\nout of on all three axes,indicating majority of factual,insightful,and fluent definitions.\\nConclusion AGCT is novel and valuable resource for biomedical tasks that require humanreadable definitions for SnomedCT concepts.\\nIt can serve as base for developing robust biomedical retrieval models or other applications that leverage natural language understanding of biomedical knowledge.\\nTo unlock value of in-hospital data while preserving patients right to privacy,federated learning might become corner stone for retrospective studies in healthcare domain Zerka et al. Inter-hospital data interoperability is,however,one of pre-requirements of federated learning Lamer et al.,and is getting attention.\\nThis has resulted in stronger appetite for more structured and more standardized coding of patient journeys through medical services Joseph et al. An issue with these standardized codes from ontologies is their usage of highly-specialized terminology Schulz et al.This diminishes their suitability for non-experts or patients wishing to consult their personal clinical data.\\nEfforts to produce simpler-to-understand definitions of biomedical concepts have been welldocumented.by Mayo Clinic but they are usually of limited scope due to time and cost involved in their creation,requiring heavy prioritization of efforts Chen et al.\\nEarly efforts to bridge gap between ontologies and textual definitions by Tsatsaronis et al.\\nand Petrova et al.remained insufficient.But in recent years, fluency of text generated using large language models has reached extremely high levels Aksitov et al.,and so has their ability to convert graph-level information into textual descriptions Ribeiro et al.\\nIn this study,authors set out to investigate suitability of commercially-available language models to generate at scale medically-accurate descriptions of clinical concepts in.To this end,authors introduce Automatic Glossary of Clinical Terminology AGCT , large-scale biomedical dictionary definitions generated using GPTOuyang et al., contained in SnomedCT ontology.\\n\\nAn overview of our prompting and definition generation strategy.\\nEach definition was obtained after prompting GPTmodel with long prompt containing summarized verbalization of SnomedCT relationships of to-be-defined concept,as well as precise instructions for generation of relevant biomedical concept definition see Annex.\\nis its data curation.For every token generated by model,four times more tokens were provided to model in its prompt,on average. hypothesis was that this saturation of information should ensure that generated definitions are well-informed and therefore factual,coupled with already impressive biomedical knowledge of GPTKung et al.,Gilson et al.\\ndefinitions were subsequently sent to be rated by NLP practitioners with biomedical expertise on three scales factuality,insight,and fluency.Each of these scales is measured using,point rating system,detailed further in.\\nTo assess factuality,annotators relied on several Internet search queries for each definition,to verify each of points mentioned in definition.This was necessary as information contained in definition was not always readily available from single initial search1.\\nAuthors provide graph representation of resulting distributions in. definitions generated by proposed methodology received good ratings across all three axes measured in this study, with average scores above.for all metrics.\\nfor Factuality.for Insight,and.for Fluency.For each metric taken separately,more than three quarters of definitions obtained highest rating on scale.\\n1for example,whether or not divergence paralysis was indeed related to an inability to move eyes outwards.\\nFactuality turned out to be rated higher than authors originally expected,with of definitions containing no incorrect information at all,and of definitions containing at most minor mistake not hurting comprehension.It seems that amount of information provided in prompts,combined with GPT5s world knowledge,was sufficient to prevent hallucinations in most cases.\\nInsight fared bit worse than Factuality however,with of definitions not containing all key elements required to properly understand defined concept.On positive note,only very small fraction of generated definitions lacked enough key elements to prevent proper understanding of defined concept.\\nFluency fared similarly to Insight,to our surprise.In most cases where fluency was deemed lacking, issue arose when model tried to include less relevant or obvious details in definitions, resulting in artificial constructions that were very easily spotted by annotators.It sounds likely that fluency could have been improved by iterating on prompt.Another common failure mode was when prompt contained too few information, and model wrote filler text to compensate.\\nfor all three axes,with correlations around or above.for all three ratings.for factuality.\\nfor insight.for fluency.This is in line with expectations for annotations by humans Frost, ,but indicates slightly too optimistic results.\\nratings of three axes among all possible one-vs-all correlations,only one metric Insight turned out to be weakly correlated.with combination of Factuality and Fluency metrics,resulting in an ability to explain around of variability in insight using two other variables combined R2.All other combinations and pairwise correlations turned out to be almost uncorrelated.This demonstrates importance of having these three independent ratings,instead of single rating for all definitions.\\ndistribution of ratings reported by annotators.\\nrating instructions,as provided to annotators.\\nBy clinical explainer ,authors mean an educative document provided to patients about their condition.\\nrules for classifying definitions into quality levels.\\nAs result of lack of correlation between three variables measured by our annotators,and of their differing importance,measuring quality of generated definition cannot be done by simple linear combination of ratings.\\ninto account criticality of factuality and lower importance of fluency,as detailed in.\\nAmong six levels,three levels of particular importance warrant further calling out Usable definitions correspond to all definitions which might be presented as-is to patient in order to help comprehension of their EHR.These definitions need perfect factuality rating and decent level of insight or more.Usable definitions are represented by green colors.\\nUseful definitions correspond to all definitions which might be relevant for machine learning models,and in particular during training of retrieval models for biomedical domain.To contrary of usable definitions,useful definitions might contain minor mistakes as long as they dont hurt comprehension of concept.Useful definitions which are not more generally usable are represented in yellow.\\nHurtful definitions correspond to all definitions which would not be relevant for machine learning models,due to too low level of factuality or below.While some definitions might not be useful or fluent at all,as long as they remain correct, machine learning models are unlikely to be mislead by them.Definitions which contain multiple minor mistakes or major mistakes might result in incorrect results however and are thus considered hurtful for our purposes.Hurtful definitions are represented in red.\\namong generated definitions in.After combining all three metrics into unified quality level,authors were able to show that more than of generated definitions were meeting quality level required for inclusion in patient explainer form,while of definitions were not.This is largely insufficient for this use case.\\nlarge majority of definitions which were not judged usable were nonetheless judged useful for machine learning purposes,with more than of definitions meeting criteria for usefulness.\\nFor scoring or pretraining other models.,in line with recent work by Remy et al., quality levels based on annotations.\\nthis appears sufficient to provide strong signal.\\n,around of remaining definitions might turn out hurtful for machine learning models,at least to some extent.Most of these definitions seem to concern less frequently used SnomedCT codes,however.This makes us confident that dataset meets requirements for usage for training retrieval models for biomedical domain,but further work might still be required before this dataset can be used for other more critical use cases in biomedical NLP.\\nIn this paper,authors introduced dataset of more SnomedCT concepts,along with an quality control procedure applicable to biomedical definitions consisting of three axes factuality,insight,and fluency and strict quality level classification based on these three axes.\\ndataset is suitable to serve as base for several biomedical pre-training tasks,for instance development of robust biomedical retrieval models, and might act as bronze standard for evaluating inherent knowledge of biomedical concepts of large language models by rating definitions they prompt. usage of definitions in user-facing scenarios is however not yet within reach.\\nauthors want to use opportunity given by this column to highlight fact that definitions generated by this procedure do not all meet standards required for presentation to users,or for reasoning-required scenarios,due to their imperfect quality.Authors release this dataset for building retreival-based systems,and evaluate large biomedical language models on definition-generation task and eventually for low-rank finetuning of existing language models.\\nIn addition to imperfect quality of generated definitions and presence of hurtful definitions in dataset,it might be useful to consider bias induced by choice of SnomedCT as our source of knowledge.\\nSnomedCT does not cover all possible relationships between concepts,and by biasing output might perpetuate existing biases in data.\\nAnother limitation is that authors only evaluate generated definitions on three metrics,but more could be relevant depending on application.\\n,our rating of what is considered acceptable insight was biased towards what could possibly be condensed in short definitions words on average ,but longer definitions might sometimes be required to express full range of nuance required by biomedical concepts.It is however difficult to estimate value of omitted information.\\nauthors do not foresee any particular ethical concern about their work,as long as it is used within guidelines outlined in article.\\nReleasing dataset prevents unnecessary replications of this experiment,possibly with less extensive QA than one presented here.\\nThis work would not have been possible without joint financial support of Vlaams Agentschap Innoveren Ondernemen VLAIO and RADar innovation center of AZ Delta hospital group.\\n, would like to thank my cosupervisors,Kris Demuynck and Thomas Demeester,for their support and constructive advice during ideation process,and all along development of this project up to this very article.\\nRenat Aksitov,Chung-Ching Chang,David Reitter,Siamak Shakeri,and Yunhsuan Sung.Characterizing attribution and fluency tradeoffs for retrievalaugmented large language models.\\nJinying Chen,Abhyuday Jagannatha,Samah Fodeh,and Hong Yu.Ranking medical terms to support expansion of lay language resources for patient comprehension of electronic health record notes Adapted distant supervision approach.JMIR Medical Informatics,e42.\\nJim Frost.Interpreting correlation coefficients.\\nAidan Gilson,Conrad Safranek,Thomas Huang, Vimig Socrates,Ling Chi,Richard Andrew Taylor, and David Chartash.How does chatgpt perform on united states medical licensing examination implications of large language models for medical education and knowledge assessment.JMIR Med Educ,e45312.\\nAmanda.Joseph,Andre.Kushniruk,and.Borycki.Patient journey mapping Current practices,challenges and future opportunities in healthcare.Knowledge Management E-Learning An International Journal.\\nTiffany.Kung,Morgan Cheatham,Arielle Medenilla, Czarina Sillos,Lorie De Leon,Camille Elepao, Maria Madriaga,Rimel Aggabao,Giezel DiazCandido,James Maningo,and Victor Tseng.\\nPerformance of chatgpt on usmle Potential for aiassisted medical education using large language models.PLOS Digital Health.\\nAntoine Lamer,Alexandre Filiot,Yannick Bouillard, Paul Mangold,Paul Andrey,and Jessica Schiro.\\nSpecifications for routine implementation of federated learning in hospitals networks.\\nhealth technology and informatics.\\nStaff Mayo Clinic.Patient care and health information,patient care and health information.\\nLong Ouyang,Jeff Wu,Xu Jiang,Diogo Almeida,Carroll.Wainwright,Pamela Mishkin,Chong Zhang, Sandhini Agarwal,Katarina Slama,Alex Ray,John Schulman,Jacob Hilton,Fraser Kelton,Luke Miller, Paul Christiano,Jan Leike,and Ryan Lowe.\\nTraining language models to follow instructions with human feedback.\\nAlina Petrova,Yue Ma,George Tsatsaronis,Maria Kissa,Felix Distel,Franz Baader,and Michael Schroeder.Formalizing biomedical concepts from textual definitions.Journal of Biomedical Semantics.\\nFranois Remy,Kris Demuynck,and Thomas Demeester.BioLORD Learning ontological representations from definitions for biomedical concepts and their textual descriptions.In Findings of Association for Computational Linguistics EMNLP Emirates.Association for Computational Linguistics.\\nLeonardo.Ribeiro,Martin Schmitt,Hinrich Schtze,and Iryna Gurevych.Investigating pretrained language models for graph-to-text generation.\\nStefan Schulz,Udo Hahn,and Jeremy.Rogers.\\nSemantic clarification of representation of procedures and diseases in snomedct.Studies in health technology and informatics.\\nStefan Schulz and Gunnar.Klein.Snomed ct advances in concept mapping,retrieval,and ontological foundations.selected contributions to .BMC Medical Informatics and Decision Making,S1.\\nGeorge Tsatsaronis,Alina Petrova,Maria Kissa,Yue Schroeder.Learning formal definitions for biomedical concepts.volume.\\nFadila Zerka,Samir Barakat,Sean Walsh,Marta Bogowicz,Ralph.Leijenaar,Arthur Jochems,Benjamin Miraglio,David Townend,and Philippe Lambin.\\nSystematic review of privacy-preserving distributed machine learning from federated databases in health care.JCO Clinical Cancer Informatics.\\nAuthors provide an non-cherry-picked sample of definitions found in our dataset.These definitions are provided as an image instead of text,despite accessibility concerns,to reduce then chance these definitions get interpreted as authoritative by machine learning model trained on scientific papers.\\ncomplete set of definitions will be available for download once dataset releases.\\nWhile entire code used to generate definitions is available in supplementary materials,authors wanted to provide in paper description of prompt used to generate definitions.\\nSystem Assistant is large language model,specialized in biomedical and clinical knowledge.\\nIt can answer questions about diseases,medications,and more.SnomedCT is medical ontology, standardized vocabulary of medical terms.It is reliable,and can be used to classify diseases and medications.\\nUser Let' talk about medical concepts. does SnomedCT say about medical concept Assistant found following facts about medical concept in SnomedCT User Ok,thanks Based on this,and your own medical knowledge,write short definition of medical concept in style of MEDLINE or UMLS.Do not give list of alternative names called in definition, user already knows about them.Include some details about required details.Leave out unimportant details if they are not useful inside short definition.Start your reply immediately by following words Based on given information,and my own medical knowledge,medical concept refers to Authors used greedy sampling,to get most likely model output.Authors decided to remove from dataset small fraction of definitions where model did not follow template,or apologized for being unable to answer ,concepts out of.\\nAlong with this paper,authors release our entire dataset on HuggingFace at following address license for this work is subject to both SnomedCT and OpenAI API agreements.\\nAuthors strongly recommend checking those licenses before making use of this dataset.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2307.07051v1.Making_the_Most_Out_of_the_Limited_Context_Length__Predictive_Power___Varies_with_Clinical_Note_Type_and_Note_Section', embedding=None, metadata={'license': 'publicdomain'}, excluded_embed_metadata_keys=['license'], excluded_llm_metadata_keys=['license'], relationships={}, hash='320305d1b9dbc584acb9319a2b6a1847bde17a4fc32f727e0b8c976f07991e5b', text='Making Most Out of Limited Context Length Predictive Power Varies with Clinical Note Type and Note Section hz2212,yz5880,lyj2002,Abstract led to renewed interest in natural language processing in healthcare using free text of clinical notes.One distinguishing characteristic of clinical notes is their long time span over multiple long documents. unique structure of clinical notes creates new design choice predictor is limited,which part of clinical notes should authors choose as input Existing studies either choose inputs with domain knowledge or simply truncate them.Authors propose predictive power.Using MIMIC-III,authors show that predictive power distribution is different between nursing notes and discharge notes and combining different types of notes could is large. findings suggest that carefully efficient information extraction from clinical notes.\\nElectronic Health Records EHR enable development of language model based clinical predictor, which takes in clinical notes to predict patient outcomes.Clinical notes in EHR exhibit two unique characteristics.Clinical notes cover long time span from few weeks to over year ,which results in their sparsity of information-rich sections.\\nClinical notes tend to be long many discharge notes could take up to ,tokens,which makes using entire note as model input computationally expensive. strong noise level in medical notes usually due to domainspecific abbreviations and typos poses challenge to extract information effectively.\\nThese distinguishing characteristics of clinical notes lead to new design choice when context length is limited due to constrained compute or model architecture,what parts of clinical notes should authors sample to maximize models performance Authors propose framework to subsample text sections with high predictive power.\\nEmpirically,authors explore distribution of predictive power over clinical note types and sections by searching over these variables.Authors found that predictive power distribution is different between nursing notes and discharge notes predictive power is stronger at beginning and end of discharge notes,while uniform within nursing notes. effect of combining sections from different types of notes improves performance when context size is large,but harms performance when context size is small.More details of task formulation can be found at section. code is publicly available on GitHub1.\\nExisting methods for subsampling clinical notes for BERT-based model are mostly based on domain knowledge.For instance,Yang et al. and Darabi et al.choose discharge notes as they summarize patients visits.Thapa et al. chooses notes within three days before cutoff time in consideration of timeliness.While these assumptions are based on domain knowledge,they require human input and may not generalize.Thus, authors are interested in exploring data-driven sampling choice without assumptions of expert inputs.\\nAnother related,but orthogonal approach to limited context length problem is note aggregation.\\nInstead of subsampling notes,Huang et al. propose to feed everything to model,one maximum context length at time,and aggregate outputs for final prediction.In their work,notes of one patient are split into partition of subsequences,and patients re-admission risk is obtained by taking weighted average of probabilities computed from each subsequence.This methods\\n\\ncompute cost scales with aggregated sequence length,which can be expensive for records with long clinical notes.In contrast,our method aims to find one single information-rich segment as input.\\nAuthors formalize our prediction task as follows given set of clinical notes associated with an admission record,authors want to predict class label which is our patient outcome of interest.Ideally, authors want to train classifier fw to approximate. optimal parameter is arg max where is metric function of interest.Nevertheless,due to computational constraint,authors need to reduce input size via sampling function so that fits input length limit and preserves information.Empirically, optimal arg max fw \\nAuthors say sample function has higher predictive power if fw , is larger.\\nmedical knowledge or simply fix it as truncation function,authors propose to explore different sampling functions to make most out of limited context length with highest predictive power.\\nNotice that in our work, and are searched manually,instead of using learning algorithms.\\nAuthors hypothesize that for,day all-cause readmission prediction,there exists an alternative sampling function that enables similar or better performance than commonly used truncated discharge notes.More formally,authors focus on parameterized sampling function with variables which section of tokens to include,what type of clinical notes to use.\\nAuthors finetuned two clinical language models in our experiments. first is Clinical-BERT Alsentzer et al.,which continued to pretrain of. second is ClinicalLongformer Li et al.,which continued to pretrain Longformer Beltagy et al.,with MIMIC-III notes and enables input of up to tokens. models are finetuned to predict probability of,day all-cause readmission that is,whether patient will be re-admitted to hospital within days of their discharge dates.\\ndatabase Johnson et al.There are , de-identified admission records available to use after filtering out all admission records without nursing notes and discharge notes. admission records are split into train.validation, and.test sets.Other types of medical notes such as physician notes are excluded from consideration in our experiments due to their scarcity in database.See Appendix for data preprocessing.\\nclinical notes,authors use sliding window technique.Let be windows width.Let be total number of tokens of text. window is placed based on an input parameter ,indicating location of midpoint of window, lp ,lp.\\nIn case where lpn ,authors shifted window backward so that front of window aligns with beginning of input tokens.In case where lp authors shifted window forward to let back of window match end of tokens.Also,when authors ignore input and pad tokens to maximum input length.\\nAuthors try different values of. for ClinicalBERT and values of and. for ClincialLongformer along with an additional fragmented window trial both which looks into first and last tokens of input text.Similarly,when authors simply pad sequence to windows length.\\nTo control different types of clinical notes,authors experimented with following options first nursing note,last nursing note, discharge note,first nursing notes discharge note,last nursing notes discharge notes.For options with two types of notes, tokens are allocated to each type,and three values for p1 and p2 each and both are used to select tokens from each type of note,resulting in possible input parameter combinations.\\nPerformance of ClinicalBERT on Different Text Sections and Different Types of Notes, Error Bars Represent Confidence Intervals Authors finetune ClinicalBERT and ClinicalLongformer on different sections of nursing and discharge notes.\\nAuthors used sliding windows to extract sequence of length.Authors have three key observations.\\nDifferent Types of Clinical Notes Show Disparate Predictive Power Distributions Over Text Sections.As shown in , discharge notes blue line show quite uneven predictive power distribution,where beginning. and end.sections of text provide strong predictive power while middle sector.shows significant dip in predictive power.In contrast, predictive power of nursing notes orange and green line turns out to be uniformly distributed using different sections of nursing notes.does not make significant difference.Authors speculate that this discrepancy may stem from domain knowledge that discharge notes are more structured than nursing notes they often start with basic descriptions of patient information and ends with suggestions for patients,whereas nursing notes often have multiple types of information mixed together throughout text.\\nNursing Notes Provide Modest Predictive Power.\\nNursing notes produce decent re-admission prediction results according to and , although their predictive power is not as strong as discharge notes which are typically written right before patients leave hospital ,they consistently achieve AUC ROC scores of over.which indicates modest predictability Schneeweiss et al. , first nursing notes orange line in ,second group of bars in of each admission provide similar predictive power as compared to last nursing notes green line in ,third group of bars in ,indicating possibility of re-admission risk evaluation at early stage of admission.This finding is especially valuable from perspective of intervention,as it is more practical to decide whether patient should be discharged at time before discharge note is written.Also, abundance of nursing notes makes them suitable alternative for re-admission risk evaluation tasks when discharge notes are unavailable.\\nDifferent Text Sections and Different Types of Notes, Error Bars Represent Confidence Intervals Performance of ClinicalBERT and ClinicalLongformer on Clinical Note Combinations, Error Bars Represent Confidence Intervals Preserving Beginning Tokens Is Not Only Option.It is generally assumed that when available input tokens are limited, leading tokens of each clinical note should be used.Nevertheless,our experiments show that for discharge notes, spending half of available tokens on beginning section and spending remaining half on end section both achieves slightly better performance AUC ROC of.versus.\\nfor ClinicalBERT.versus.for ClinicalLongformer as compared to using leading token only.Authors speculate that this helps as it avoids weakly predictive middle sector of clinical notes.\\ntypes of clinical notes and finetune ClinicalBERT and ClinicalLongformer.This experiment helps information from different clinical notes work predictive power in our prior experiments,authors only investigate note type combinations that include discharge notes first nursing discharge,last nursing discharge.\\nTypes of Clinical Notes Depends on Context Size.When context size is relatively large ClinicalLongformer,as shown in right side of figure ,allocating available tokens to different types of clinical notes blue,orange,and green bars leads to improvements in performance. baseline dashed red line uses discharge notes only and has lower AUC ROC.to.than models finetuned with combined notes., when context is small Clinical BERT,as shown in left side of figure ,distributing already limited number of tokens to different clinical notes hurts performance AUC ROC of ClinicalBERT finetuned with mixed notes falls below baseline performance by.to.Authors speculate that this may be related to uneven predictive power distribution in discharge notes if there are already sufficient number of tokens covering most informative sections of discharge notes, rest of discharge notes might not be as informative as prior nursing notes.\\nfindings suggest that when input size is constrained, carefully selected sampling function that chooses text with high predictive power could benefit model performance.Specifically on task of readmission prediction from MIMIC-III notes,authors show that predictive power varies across note types and note sections.This insight enables more efficient information extraction from long and noisy clinical notes,which is beneficial when computing resource is limited and context length needs to be controlled.\\nfindings call for two future directions.First, performance disparities between ClinicalBERT and ClinicalLongformer subsection.indicate that best strategy to allocate input context is related to maximum sequence length,and more work should be done to determine their exact relationship.Another direction is investigating predictive power pattern based on authorship of clinical note.Authors showed subsection.that discharge notes written by doctors have more uneven predictive power pattern as compared to nursing notes written by nurses.How domain knowledge of author would affect clinical note quality is worth investigating.\\nAuthors acknowledge three limitations in our experiments.First,in our second experiment,authors fixed window size for each type of note to be.\\nsearch for optimal window size for each note type.\\nSecond,although authors explored one fragmented window configuration both,authors did not explore other fragmented window configurations due to resource constraints.Lastly,authors did not investigate more types of clinical notes.,physician notes and ECG notes because MIMIC-III has limited examples for other note types.Authors expect it to be resolved in future works with MIMIC-IVs publication Johnson et al.\\nEmily Alsentzer,John.Murphy,Willie Boag,WeiHung Weng,Di Jin,Tristan Naumann,and Matthew.McDermott.Publicly available clinical bert embeddings.\\nIz Beltagy,Matthew.Peters,and Arman Cohan.\\nLongformer long-document transformer.,\\n\\nSajad Darabi,Mohammad Kachuee,Shayan Fazeli,and Majid Sarrafzadeh.Taper Time-aware patient ehr representation.IEEE Journal of Biomedical and Health Informatics.\\nKexin Huang,Jaan Altosaar,and Rajesh Ranganath.\\npredicting hospital readmission.\\n\\nAlistair Johnson,Lucas Bulgarelli,Lu Shen,Alvin Gayles,Ayad Shammout,Steven Horng,Tom Pollard, Sicheng Hao,Benjamin Moody,Brian Gow,Li-wei Lehman,Leo Celi,and Roger Mark.Mimic-iv, freely accessible electronic health record dataset.\\nScientific Data.\\nAlistair.Johnson,Tom.Pollard,Lu Shen,Li wei.Lehman,Mengling Feng,Mohammad Ghassemi, Benjamin Moody,Peter Szolovits,Leo Anthony Celi, and Roger.Mark.Mimic-iii, freely accessible critical care database.Nature.\\nYikuan Li,Ramsey.Wehbe,Faraz.Ahmad,Hanyin Wang,and Yuan Luo.Clinical-longformer and clinical-bigbird Transformers for long clinical sequences., Maclure,Philip Wang,Jerry Avorn,and Robert Glynn.Performance of comorbidity scores to control for confounding in epidemiologic studies using claims data.American journal of epidemiology \\nNischay Bikram Thapa,Sattar Seifollahi,and Sona Taheri.Hospital readmission prediction using clinical admission notes.In Australasian Computer Science Week ,pages.\\nGrace Yang,Ming Cao,Lavender Jiang,Xujin Liu,Alexander Cheung,Hannah Weiss,Davied Kurland,Kyunghyun Cho,and Eric Oermann.\\nLanguage model classifier aligns better with physician word sensitivity than xgboost on readmission prediction. Authors preprocessed dataset with following approach First of all,admission records with missing discharge notes or missing nursing notes are eliminated.Then,for each remaining admission record, nursing notes associated with that record are sorted according to their timestamp. first and last created nursing notes for each admission are selected and concatenated with discharge notes of same admission record to produce clinical note set for every admission.Lastly,authors clean datasets by removing de-identification patterns de-identified info in clinical notes, which usually occupy lot of tokens.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2307.07513v1.An_empirical_study_of_using_radiology_reports_and_images_to_improve_ICU___mortality_prediction', embedding=None, metadata={'license': 'publicdomain'}, excluded_embed_metadata_keys=['license'], excluded_llm_metadata_keys=['license'], relationships={}, hash='83c8b2ddb4d272d83bb6b0db5ae582592ab5c23a7978a4d2bb16962549823b31', text='An empirical study of using radiology reports and Mingquan Lin1,Song Wang2,Ying Ding3,Lihui Zhao4, Fei Wang1,Yifan Peng1 1Department of Population Health Sciences,Weill Cornell Medicine, New York,USA.\\n2Cockrell School of Engineering, University of Texas at Austin, Austin,USA.\\n3School of Information, University of Texas at Austin,Austin,USA.\\n4Department of Preventive Medicine,Northwestern University,Chicago, USA.\\nCorresponding author.E-mail These authors contributed equally to this work.\\nBackground predictive Intensive Care Unit ICU scoring system plays an important role in ICU management because it predicts important outcomes, especially mortality.Many scoring systems have been developed and used in ICU.These scoring systems are primarily based on structured clinical data in electronic health record EHR ,which may suffer loss of important clinical information in narratives and images.\\nMethods In this work,authors build deep learning based survival prediction model with multi-modality data to predict ICU mortality.Four sets of features are investigated physiological measurements of Simplified Acute Physiology Score SAPS II,common thorax diseases pre-defined by radiologists, BERT-based text representations,and chest X-ray image features.Authors use Medical Information Mart for Intensive Care IV MIMIC-IV dataset to evaluate proposed model.\\nResults model achieves average C-index of.confidence interval.,which substantially exceeds that of baseline with SAPS-II features.Ablation studies further demonstrate contributions of pre-defined labels.,text features.,and image features.\\n\\nConclusions model achieves higher average C-index than traditional machine learning methods under same feature fusion setting,suggesting that deep learning methods can outperform traditional machine learning methods in ICU mortality prediction.These results highlight potential of deep learning models with multimodal information to enhance ICU mortality prediction.Authors make our work publicly available at mimic-icu-mortality.\\nKeywords Mortality prediction,Deep learning,Multimodal fusion Predictive ICU scoring systems measure disease severity to predict outcomes, typically mortality,of patients in intensive care unit ICU.Such measurements help standardize research and compare quality of patient care across ICUs.For example, Acute Physiology and Chronic Health Evaluation ,Simplified Acute Physiology Score SAPS II ,and Mortality Probability Model were created explicitly for use in ICU,validated in critically ill,and relied primarily on physiologic data to predict mortality.These scoring systems have been primarily based on structured clinical data including risk factors used by scoring system such as demongraphsics,vital signs and lab tests,which are frequently documented in electronic health record EHR.\\nrecent development of machine learning offers great potential to improve ICU mortality prediction.,these studies used only structured,coded approaches for data entry,thus may result in loss of significant clinical information typically contained in narratives and images.To overcome this issue, many studies focus on mining unstructured clinical notes for patient mortality prediction.,most of these works were not compared with current scoring system,making it challenging to compare these models fairly.\\n, practice of modern medicine usually relies on multimodal information.Consequently,many feature fusion strategies were proposed to enhance performance of prediction algorithms,such as early fusion,late fusion,and joint fusion.Early fusion combines multimodal features into single vector by concatenating or averaging.Late fusion combines predictions of multiple models to make final decision.Joint fusion combines features from intermediate layer of neural network with features of other modalities. loss during training process will propagate back to feature extraction neural network, thereby creating better feature representation through training iterations Despite these encouraging findings,authors note that most competitive approaches studied classification tasks.Thus, integration of text and images in survival analysis framework remains an important yet,to date,insufficiently studied problem.\\nAuthors,therefore,sought to overcome these limitations by incorporating potentials of natural language processing NLP and medical image analysis to identify hidden features of critical illness among ICU patients in radiology reports and chest X-rays that may not be found in structured EHR fields and investigating deep learning models that may provide superior discrimination of ICU mortality predictions compared to traditional machine learning models.Specifically,authors first build clinical prediction models to predict ICU mortality using SAPSII risk factors such as demographics,vital signs,and lab tests.These measurements were obtained in first hours of ICU admission.Authors then enrich model with multimodal features extracted from radiology reports and chest X-rays. radiology imaging and reading were studied in first hours.Authors hypothesize that including free texts and images provides better predictions of ICU mortality than including clinical measurements alone.Experiments on MIMIC-IV dataset show that our multimodal models are substantially more accurate than unimodal ones.\\nframework has several important strengths.First,authors present method to fuse multimodal data from EHR for ICU mortality prediction.Second,authors demonstrate that our survival analysis model outperforms existing clinical standards SAPS-II.\\nThird,authors make our work publicly available for reproduction by others.\\nTask Authors first formulate survival analysis task,which predicts patients survival probability in ICU as function of their features.Authors have patients xi,yi Each patient record consists of potential covariants xi Rd,and time Ti when death occurred or time Ci of censoring.Since death and censoring are mutually exclusive,authors use indicator ,and observed survival time yi,defined as below.\\nyi min Ti,Ci if if goal is to estimate survival probability Si Pri of patient who was not dead beyond time.\\nIn this study,authors use one of most popular survival analysis models, Cox model ,where survival function is assumed to be Si xi S0 xi.\\nIn this model,S0 is baseline survival function that describes risk for individuals with xi ,and xi xi is relative risk based on covariants.\\nNote that S0 is shared by all patients at time.It is NOT associated with any individual covariants. effect of covariate values xi on survival function is to raise it to power given by relative risk.\\nIn Cox model,xi has form of linear function,but authors can extend it to non-linear risk function of neural network,called DeepSurv-based model.\\nDeepSurv-based model has three steps features extraction,multimodal feature fusion,and survival analysis. main difference between our model and DeepSurv model in is that our deep network performs multimodal feature fusion.When there is only single modality as input,our model is equivalent to DeepSurv model.\\ndetail of neural network via feature fusion is as described in next section.\\nNeural network via feature fusion practices of physicians rely heavily on synthesis of data from multiple sources.\\nThis includes,but is not limited to,structured laboratory data,unstructured text data, and imaging pixel data.Therefore,automated predictive models that can successfully utilize multimodal data may lead to better performance.\\nIn this paper,authors expand xi by introducing deep neural network with fusion features from multiple sources SAPS-II risk factors xsaps,text features xtext, and imaging features ximg. extracted text features xtext and image features ximg are respectively passed to two separate Multilayer Perceptron MLP modules where output dimensions are equal.Authors then use two hidden features by element-wise averaging.,authors concatenate it to xsaps.\\nxi Avg DNNimg ximg ,DNNtext xtext xsaps In terms of fusion strategy,our approach is similar to early fusion which refers to process of combining features from multiple input modalities into one single feature vector before feeding into survival model. difference is that our loss is propagated back to DNNs during training,thus creating better feature selections for each training iteration.In addition,our approach is not joint fusion because parameters of features are not updated during training iteration.\\nGCN Fig.Multimodal feature fusion network.\\nFeature Extraction.SAPS-II score and risk factors SAPS-II was designed to measure severity of disease for patients aged or more admitted to ICU.Twenty-four hours after admission to ICU, measurements have been completed and resulted in an integer point score between and. score is calculated from routine physiological measurements including information about previous health status,and some information obtained at admission.These measurements are Age,Heart rate,Blood pressure,Temperature,PaO2 FiO2,Blood urea nitrogen,Urine output,Sodium,Potassium,Bicarbonate,Bilirubin,White blood count,Glasgow Coma Scale,Chronic disease,and Admission type.\\nText Features In this work,authors investigate three sets of text features.\\nCommon thorax diseases from radiology reports. first set of features consists of pre-defined diseases commonly found in radiology reports Atelectasis, Cardiomegaly,Consolidation,Edema,Enlarged Cardiomediastinum,Fracture,Lung lesion,Lung opacity,Pleural effusion,Pleural other,Pneumonia,Pneumothorax,Support devices and Normal.These labels were extracted from radiology reports using NegBio and can be obtained from MIMIC-CXR website1.\\nTransformer-based features. second set of features are text embeddings extracted by BERT model,taking advantage of pre-training on large-scale biomedical and clinical text corpora.Utilizing clinical texts in survival analysis is difficult because they are largely unstructured. above lung diseases may fail to capture textual information comprehensively since their labels are still limited in scope.In this work,authors use BERT-based hidden layer representations as text features.For an input report that contains tokens, BERT model will produce d-dimension embedding vector for each token,resulting in an representation vector of report in latent space.Authors apply average pooling over token embeddings from last layer of BERT model to obtain an aggregate latent report representation.\\nGCN-based features.Authors build graph convolutional neural network GCN to model inner correlations among radiology concepts. graph was manually defined by domain experts in Zhang et al.Disease findings are defined as nodes in graph,and correlated findings are connected to influence each other during graph propagation.Authors take hidden representation vectors from last layer of BERT model.To initialize GCN node features,authors apply 1dimension convolution over text features with kernel size and number of output channels equal to number of graph nodes.In this way, graph nodes are initialized by aggregating hidden features of all tokens in report.\\nGCN updates its node representations by message passing.Authors first calculate D1 AD1 in pre-processing step.IN is adjacency matrix with added self-connections,where is graph adjacency matrix,IN is Ndimension identity matrix, diag Aij is diagonal node degree matrix.Then based on , graph convolution can be expressed as Hl ReLu AH0W b0 softmax AH1W b1 where Hl is states in l-th layer,with H0 initialized using aggregate report text hidden features,and is trainable layer-specific weights matrix.\\nImage Features For image feature extraction,authors use ChexNet, DenseNet,model pretrained on CheXpert dataset.For each input image,authors extract image features of dimension dimg from global average pooling layer of DenseNet\\nStudy population and patient selection Authors use MIMIC-IV dataset Medical Information Mart for Intensive Care IV to evaluate proposed model.MIMIC-IV is de-identified clinical database composed of ,patients admitted in ICUs at Beth Israel Deaconess Medical Center.Of those,authors excluded patients who had no CXR studies before measurements have been completed and resulted in SAPS-II score.Therefore,there are in total ,patients included in this study.Out of these patients,patients were deceased in ICU.lists information of ICU admission group studied in this work.Details of SAPS-II can be found in A1.\\nEvaluation metrics To assess accuracy of our models,authors use C-index,defined as Ls where otherwise ,dj otherwise, and.is number of sample.\\nIntuitively, C-index measures extent to which model can assign logical risk scores.An individual with shorter time-to-event should have higher risk score than those with longer time-to-event.C-index assigns random model.\\nand perfect model.\\nInformation of ICU admission group.EC Enlarged Cardiomediastinum.\\nGender,male female, Race, Black African American Hispanic Latino Common thorax diseases Implementation and Experimental Settings Authors perform grid search to find optimal hyperparameters based on metrics and use them for all configurations. MLP layer for SAPS-II risk factors takes an input of dimensions,and fully connects to output dimensions. MLP layer for labels features fully connects ,dimension inputs to ,dimension outputs.\\nMLP layer for report text features fully connects ,dimension inputs to ,dimension outputs,and MLP layer for chest X-ray image features fully connects ,dimension inputs to ,dimension outputs.\\nAuthors use bootstrap samples to obtain distribution of C-index and report confidence intervals CI.For each bootstrap experiment,authors sample patients with replacement from whole set of patients.Authors then split sampled set into training ,validation ,and test sets.Authors iterate training process for epochs with batch size and early stop if validation loss does not decrease.\\ndropout rate is. learning rate is.with an Adam optimizer.\\nAuthors obtained SAPS-II scores using scripts in MIMIC-IV repository2.\\ntext embeddings are extracted using BlueBERT ,which was pre-trained on PubMed abstracts and MIMIC-III notes.Authors use pycox3,scikit-survival ,and PyTorch to implement framework.Intel Core i9-9960X cores processor and NVIDIA Quadro RTX GPU are used in this work.\\nAuthors first compare baseline ICU scoring model and our models with four different feature settings. SAPS-II score is an integer point score between and directly obtained from MIMIC-IV website. SAPS-II risk factors model is trained using routine physiological measurements. SAPS-II risk factors GCN features model is enriched with GCN-based features. SAPS-II risk factors Image features model is enriched with chest X-ray image features. multimodal features model is trained using SAPS-II risk factors combined with text features and chest X-ray image features using early average fusion.\\nshows that ICU scoring model achieves an average C-index of.\\nconfidence interval. mean C-index of our model with SAPSII risk factors achieves.,which brings.improvements to ICU scoring baseline model.When combining SAPS-II risk factors with GCNbased text features and image features, models obtain average C-index of and.,respectively,yielding increases of and.Using multimodal features, performance of model can further be boosted.Authors obtain average C-index of.,resulting in an improvement of.over ICU scoring model.Authors train multimodal features model with SAPS-II risk factors combined with GCN features and chest X-ray image features using early average fusion. average C-index is.,which is slightly lower than proposed multimodal features model.\\nC-index comparisons of models using different sets of features.\\nCI.. SAPS-II risk factors GCN features. SAPS-II risk factors Image features.. shows more details on bootstrapping. violin shape reflects distribution of C-index thicker, higher frequency.Authors find that average C-index associated with multimodal features model is statistically higher than other four settings.\\nshows C-index results of our SAPS-II risk factors model and multimodal features model,marked in red and blue respectively. are trained on entire dataset and tested on patients with normal or abnormal chest X-rays.It is clear that our multimodal features model outperforms SAPS-II risk factors model and normal subjects can be more accurately predicted by our model. further breaks chest X-ray abnormalities into pre-defined thorax diseases.\\nFactors GCN Factors Image Fig.C-index comparisons of models using different sets of features.pvalue. pvalue.\\nFig. C-index results of models trained on entire dataset and tested on normal patients or patients with chest X-ray abnormalities.\\nComparison of different types of text features.\\nFirst,authors compare results of our model using different types of text features.SAPSII risk factors labels,SAPS-II risk factors transformer features,and SAPS-II risk factors GCN features.They are trained using routine physiological measurements combined with thorax disease labels,transformer-based features,and GCN-based features,respectively.lists results of our model using these three feature settings. mean C-indexes for these three settings are.,and.,respectively.Models with Fig. C-index results of models trained on entire dataset and tested on patients with different chest X-ray abnormalities.\\ntransformer features or GCN features outperform model that uses only labels.But there is no significant difference between transformer and GCN features.\\nC-index results of models using different types of text features.\\nCI SAPS-II risk factors labels. SAPS-II risk factors transformer features. SAPS-II risk factors GCN features..Contribution of thorax diseases in survival analysis Next,authors analyze multivariate association of chest X-ray abnormalities to ICU mortality based on Cox Proportion Hazards CoxPH model. p-values of these four findings enlarged cardiomediastinum,fracture,pneumonia,pneumothorax are greater than.,indicating that there is no statistically significant difference.In other words,these findings do not contribute to mortality prediction.\\nComparison of linear and deep survival models Authors then compare performances of linear machine learning model and deep learning model CoxPH and DeepSurv-based model.\\nMultivariate associations of chest X-ray abnormalities to ICU-mortality.pvalue.pvalue.pvalue.\\nCI.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nshows results for both models with two feature settings. average C-indexes of CoxPH model with SAPS-II risk factors and SAPS-II risk factors labels are and.,respectively,in comparison with and.obtained by our DeepSurv-based model. results demonstrate that deep learning models outperform CoxPH on high-dimensional features. p-value for CoxPH and DeepSurv-based model using SAPS-II is and p-value is.08e,when using SAPS-II labels.\\nC-index results of conventional machine learning models and deep learning models trained and tested on entire dataset.\\nCI.. SAPS-II risk factors labels...Error Analysis Error analysis.,examining reasons behind inaccurate predictions revealed that multimodal accounted for fewer errors.demonstrates one example case of ICU mortality.According to physiological measurements,SAPS-II graded patient score of and patient.,patient was decreased at hour ,but patient was deceased at hour.Hence, SAPS-II incorrectly assigned score.\\n,our multimodal approach correctly assigned higher survival probability to patient.than to patient.In one bootstrap sample,authors observed total of ,such errors patient has normal chest x-ray,and SAPSII gives wrong predictions but our multimodal method gives correct predicitons with ,distinct patients,out of which patients have normal chest X-rays and , patients have abnormal chest x-rays.shows distribution of thorax diseases among ,patients.It shows that Lung Opacity.contributes most to ICU mortality prediction.\\nFig.Distribution of thorax diseases among patients where our multimodal model made more accurate predictions than SAPS-II.\\nIn this paper,authors propose deep learning method that combines text and image features that may not be found in structured EHR field before,to improve ICU mortality prediction.Experiments on MIMIC-IV dataset show that our multimodal features model using SAPS-II risk factors and early fusion of text and X-ray image features obtains superior average C-index of. than several baselines.This demonstrates that additional information provided by multimodal features can improve ICU mortality prediction performance.\\nAuthors investigate whether deep learning methods are more powerful than traditional machine learning methods in predicting ICU mortality.Through experiments, our model achieves better average C-index than CoxPH model under same feature fusion setting,proving superior performance of deep learning methods in ICU mortality prediction.\\nThere are several limitations to this work.First,authors use fusion strategy similar to early fusion to fuse text and image features extracted by BlueBERT and ChexNet,respectively,but parameters of them are not updated during training iterations.In future,authors plan to use joint fusion to propagate loss back to feature extraction modules during training,which may improve representation learning performance.Second, knowledge graph is popular tool for representing background knowledge,which can improve several aspects of model.Authors will explore other domain knowledge and try different ways of incorporating knowledge graph into ICU mortality prediction.Third, longitudinal EHR data contain information regarding disease progressions that may help ICU mortality prediction,but are not utilized in this work.In future,authors can employ longitudinal EHR to assist in predicting ICU mortality.Fourth,there is risk of selction bias in this study.For instance,authors only included in our analysis patients with imaging studies after ICU admission.Imaging studies are usually performed when patient is sicker, for example,to confirm central line placement.This selection could lead to sample that is not representative of ICU population.,selection bias is common problem in machine learning ,statistics ,and epidemiology as result, number of techniques have been developed to correct it.In future,authors will investigate these techniques.Fifth,machine learning models are vulnerable to adversarial attacks.For example,images can be attacked by adding small perturbation to original images.Texts can be attacked by adding small number of words.These attacks are imperceptible to humans but mislead model into producing incorrect outputs.Like selection bias, adversarial attack is common problem in medical domain,where accurate diagnostic results are of paramount importance.Previous studies suggest that if model could eliminate noises in their learned feature representations,they would be more robust against adversarial perturbations.Authors will study these techniques to improve robustness of model in future.\\nWhile our work only scratches surface of multimodal fusion for survival analysis,authors hope it will shed light on future directions for ICU mortality prediction.\\nSupplementary information.\\nAbbreviations.\\nMIMIC Medical Information Mart for Intensive Care Ethics approval and consent to participate.\\ndataset supporting conclusions of this article is available in Medical Information Mart for Intensive Care version IV MIMIC-IV ,which is public de-identified database thus informed consent and approval of Institutional Review Board was waived. access to database was approved after completion of Collaborative Institutional Training Initiative CITI program web-based training.\\nConsent for publication.\\nAvailability of data and materials.\\nwork is Medical Information Mart for Intensive Care IV MIMIC-IV ,which is Competing interests.\\nauthors declare that they have no competing interests.\\nFunding.\\nThis work was funded by National Library of Medicine under award number 4R00LM013001 and Amazon Machine Learning Grant.\\nAuthors contributions.\\nML and SW implemented methods,conducted experiments and wrote paper.YP advised on all aspects of work involved in this project and assisted in paper writing.YD,LZ,and FW advised on overall direction of project and edited paper.All authors read and approved final manuscript.\\nA1 SAPS-II physiological measurements of ICU admission group.\\nPaO2 FiO2,mm Hg Blood urea nitrogen,mg dL Urine output,mL day Sodium,mEq.\\n\\nor.\\nBicarbonate,mEq Bilirubin,mg dL.\\n\\n\\nWhite blood count,x103 mm3.\\n\\n\\nLipshutz.,Feiner.,Grimes.,Gropper.Predicting mortality in intensive care unit comparison of university health consortium expected probability of mortality and mortality prediction model iii.Journal Zimmerman.,Kramer.,McNair.,Malila.Acute physiology and chronic health evaluation apache iv hospital mortality assessment for todays critically ill patients.Critical care medicine , Le Gall.,Lemeshow.,Saulnier.new simplified acute physiology score saps ii based on european north american multicenter study.JAMA , Teres.,Lemeshow.,Avrunin.,Pastides.Validation of mortality prediction model for icu patients.Critical care medicine , El-Rashidy.,El-Sappagh.,Abuhmed.,Abdelrazek.,El-Bakry. Intensive care unit mortality prediction An improved patient-specific stacking ensemble model.IEEE Access , An example case of ICU mortality prediction where our multimodal model made more accurate prediction than SAPS-II.According to physiological measurements,SAPS-II graded patient score of and patient.,patient was decreased at hour ,but patient was deceased at hour.Hence, SAPS-II incorrectly assigned score.,our multimodal approach correctly assigned higher survival probability to patient.to patient.\\nFINDINGS Portable AP chest radiograph demonstrates no focal consolidation,pleural effusion,pulmonary vascular engorgement,or pneumothorax.Multiple vascular stents are noted in right upper extremity,superior mediastinum,and mid left upper extremity. aorta is tortuous. cardiomediastinal silhouette is otherwise normal.\\nIMPRESSION No acute cardiopulmonary process.\\nright lung compatible with components of pleural effusion and postobstructive consolidation secondary to known right chest mass.,there is increasing left pleural effusion with basilar atelectasis.Assessment of heart size is limited due to these opacities.There is no pneumothorax.\\nright-sided pleural effusion and postobstructive consolidation in setting of known right chest mass increasing left pleural effusion with basal atelectasis.\\nGhassemi.,Pimentel.,Naumann.,Brennan.,Clifton.,Szolovits ,Feng.multivariate timeseries modeling approach to severity of illness assessment and forecasting in icu with sparse,heterogeneous clinical data.In Proceedings of AAAI Conference on Artificial Intelligence,vol. Zhao.,Chen.,Hou.,Graham.,Li.,Richman.,Thode., Singer.,Duong.Prediction model and risk scores of icu admission and mortality in covidPloS one , Johnson.,Mark.Real-time mortality prediction in intensive care unit.In AMIA Annual Symposium Proceedings,vol.\\nMurdoch.,Detsky. inevitable application of big data to health care.Jama , Ching.,Himmelstein.,Beaulieu-Jones.,Kalinin.,Do., Way.,Ferrero.,Agapow.,Zietz.,Hoffman.,et al.Opportunities and obstacles for deep learning in biology and medicine.Journal of Mechcatie.,Rosenberg.Nursing notes are predictive of outcomes in icu patients.AJN American Journal of Nursing , Yang.,Kuang.,Xia.Multimodal temporal-clinical note network for mortality prediction.Journal of Biomedical Semantics , Grnarova.,Schmidt.,Hyland.,Eickhoff.Neural document embeddings for intensive care patient mortality prediction.\\n\\nHuang.,Pareek.,Seyyedi.,Banerjee.,Lungren.Fusion of medical imaging and electronic health records using deep learning systematic review and implementation guidelines.npj Digital Medicine , Liu.,Wang.,Jin.,Gao.,Dellandrea.,Chen.Visual affective classification by combining visual and text features.PloS one , Liu.,Chen.,Lan.,Lin.,Chen.,Wang.,Li.,Yang.,Zhao ,Hu.,et al.Prediction of rupture risk in anterior communicating artery aneurysms with feed-forward artificial neural network.European radiology Liu.,Lan.,Chen.,et al.Bone age assessment model based on multidimensional feature fusion using deep learning.Academic Journal of Second Bakkali.,Ming.,Coustaty.,Rusinol.Visual and textual deep feature fusion for document image classification.In Proceedings of IEEE CVF Conference on Computer Vision and Pattern Recognition Workshops,pp. Reda.,Khalil.,Elmogy.,Abou El-Fetouh.,Shalaby.,Abou ElGhar.,Elmaghraby.,Ghazal.,El-Baz.Deep learning role in early diagnosis of prostate cancer.Technology in cancer research treatment , Qiu.,Chang.,Panagia.,Gopal.,Au.,Kolachalama. Fusion of deep learning models of mri scans,minimental state examination,and logical memory test enhances diagnosis of mild cognitive impairment.Alzheimers Dementia Diagnosis,Assessment Disease Monitoring , Yala.,Lehman.,Schuster.,Portnoi.,Barzilay.deep learning mammography-based model for improved breast cancer risk prediction.Radiology Kawahara.,Daneshvar.,Argenziano.,Hamarneh.Seven-point checklist and skin lesion classification using multitask multimodal neural nets.IEEE journal of biomedical and health informatics , Yoo.,Tang.,Li.,Metz.,Kolind.,Traboulsee.,Tam. Deep learning of brain lesion patterns and user-defined clinical and mri features for predicting conversion to multiple sclerosis from clinically isolated syndrome.\\nComputer Methods in Biomechanics and Biomedical Engineering Imaging Ford.,Carroll.,Smith.,Scott.,Cassell.Extracting information from text of electronic medical records to improve case detection systematic review.Journal of American Medical Informatics Association Weissman.,Hubbard.,Ungar.,Harhay.,Greene., Himes.,Halpern.Inclusion of unstructured clinical text improves early prediction of death or prolonged icu stay.Critical care medicine , Johnson.,Bulgarelli.,Pollard.,Horng.,Celi.,Mark.MIMICIV.PhysioNet. Wang.,Peng.,Lu.,Lu.,Bagheri.,Summers.Chestx-ray8 hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases.In IEEE Conference on Computer Vision and Pattern Recognition CVPR ,pp.IEEE Katzman.,Shaham.,Cloninger.,Bates.,Jiang.,Kluger. Deepsurv personalized treatment recommender system using cox proportional hazards deep neural network.BMC medical research methodology , Irvin.,Rajpurkar.,Ko.,Yu.,Ciurea-Ilcus.,Chute.,Marklund., Haghgoo.,Ball.,Shpanskaya.,et al.Chexpert large chest radiograph dataset with uncertainty labels and expert comparison.In Proceedings of AAAI Conference on Artificial Intelligence,vol.,pp. Johnson.,Pollard.,Greenbaum.,Lungren.,Deng., Peng.,Lu.,Mark.,Berkowitz.,Horng.MIMIC-CXR-JPG, large publicly available database of labeled chest radiographs. Peng.,Wang.,Lu.,Bagheri.,Summers.,Lu.NegBio highperformance tool for negation and uncertainty detection in radiology reports.In AMIA Joint Summits on Translational Science Proceedings.AMIA Joint Summits on Translational Science,vol.,pp. Zhang.,Wang.,Xu.,Yu.,Yuille.,Xu.When radiology report generation meets knowledge graph.ArXiv Kipf.,Welling.Semi-Supervised Classification with Graph Convolutional Networks.In Proceedings of 5th International Conference on Learning Representations.ICLR. Huang.,Liu.,Van Der Maaten.,Weinberger.Densely connected convolutional networks.In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition,pp. Rajpurkar.,Irvin.,Zhu.,Yang.,Mehta.,Duan.,Ding.,Bagul ,Langlotz.,Shpanskaya.,et al.Chexnet Radiologist-level pneumonia detection on chest x-rays with deep learning. Kingma.,Ba.Adam method for stochastic optimization.\\n\\nPeng.,Yan.,Lu.Transfer learning in biomedical natural language processing An evaluation of bert and elmo on ten benchmarking datasets.In Proceedings of Workshop on Biomedical Natural Language Processing BioNLP ,pp. Polsterl.scikit-survival library for time-to-event analysis built on top of scikit-learn. Journal of Machine Learning Research , Cortes.,Mohri.,Riley.,Rostamizadeh.Sample selection bias correction theory.In Algorithmic Learning Theory 19th International Conference, ALT ,Budapest,Hungary,October Proceedings ,pp..Springer Whittemore.Collapsibility of multidimensional contingency tables.Journal of Royal Statistical Society Series Methodological , Robins.Data,design,and background knowledge in etiologic inference.\\nGoodfellow.,Shlens.,Szegedy.Explaining and harnessing adversarial examples. Paschali.,Conjeti.,Navarro.,Navab.Generalizability vs.robustness investigating medical imaging networks using adversarial examples.In Medical Image Computing and Computer Assisted InterventionMICCAI 21st International Conference,Granada,Spain,September -,Proceedings,Part pp.Springer Finlayson.,Bowers.,Ito.,Zittrain.,Beam.,Kohane. Adversarial attacks on medical machine learning.Science ,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update metadata and exclusions\n",
    "def update_documents(documents):\n",
    "    for document in documents:\n",
    "        # retain the filename\n",
    "        document.id_ = document.id_.split('/')[-1].split('.txt')[0]\n",
    "        document.excluded_embed_metadata_keys = ['license']\n",
    "        document.excluded_llm_metadata_keys = ['license']\n",
    "update_documents(documents)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_window=2048 num_output=384 is_chat_model=False is_function_calling_model=False model_name='unknown'\n"
     ]
    }
   ],
   "source": [
    "def get_service_context(model):\n",
    "    # define LLM\n",
    "    llm=KronOpenAI(temperature=0.01, model=model)\n",
    "    #chunk_size+prompt_length+expected length of returned triples must be less than max_tokens\n",
    "    llm.max_tokens = 384 #192-48\n",
    "    llm_predictor = KronLLMPredictor(llm)\n",
    "    print(llm_predictor.metadata)\n",
    "\n",
    "    # define TextSplitter\n",
    "    text_splitter = SentenceSplitter(chunk_size=192, chunk_overlap=48, paragraph_separator='\\n')\n",
    "\n",
    "    #define NodeParser\n",
    "    node_parser = SimpleNodeParser(text_splitter=text_splitter)\n",
    "\n",
    "    #define ServiceContext\n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, node_parser=node_parser)\n",
    "\n",
    "    return service_context\n",
    "\n",
    "service_context = get_service_context(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "s3_fs = s3fs.S3FileSystem(\n",
    "    key = AWS_ACCESS_KEY_ID,\n",
    "    secret = AWS_SECRET_ACCESS_KEY,\n",
    "    endpoint_url= AWS_ENDPOINT_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#html-kg is the bucket name for html and indices-kg is the bucket name for indices\n",
    "HTML_FOLDER = f\"html-kg/{INDEX_NAME}\"\n",
    "persist_path = f\"indices-kg/{INDEX_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create pyvis graph\n",
    "## use generate_html with a s3 write\n",
    "def save_pyvis_network_graph(index, file_name):\n",
    "    #display all nodes\n",
    "    g = index.get_networkx_graph(limit = 6000)\n",
    "    net = Network(height='1000px', width='100%', notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "    net.from_nx(g)\n",
    "    html_name = f'{HTML_FOLDER}/{file_name}.html'\n",
    "    #print(html_name)\n",
    "    #net.show(html_name)\n",
    "    html = net.generate_html(html_name)\n",
    "    s3_fs.write_text(html_name, html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not s3_fs.exists(persist_path):\n",
    "    print('No KGIndex found, creating new empty index.')\n",
    "    graph_store = SimpleGraphStore()\n",
    "    storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "    index = KnowledgeGraphIndex(\n",
    "        [],\n",
    "        max_triplets_per_chunk=2,\n",
    "        storage_context=storage_context,\n",
    "        service_context=service_context,\n",
    "    )\n",
    "    index.storage_context.persist(persist_dir=persist_path, fs=s3_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from indices-kg/Writer-camel-5b-hf-default-no-coref\n",
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Processing: 2211.01705v1.A_speech_corpus_for_chronic_kidney_disease\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPConnectionPool(host='10.0.0.222', port=30307): Max retries exceeded with url: /v1/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcc111add30>: Failed to establish a new connection: [Errno 111] Connection refused')).\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPConnectionPool(host='10.0.0.222', port=30307): Max retries exceeded with url: /v1/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcc111cd1c0>: Failed to establish a new connection: [Errno 111] Connection refused')).\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPConnectionPool(host='10.0.0.222', port=30307): Max retries exceeded with url: /v1/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcc111cd5b0>: Failed to establish a new connection: [Errno 111] Connection refused')).\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPConnectionPool(host='10.0.0.222', port=30307): Max retries exceeded with url: /v1/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcc111cdbb0>: Failed to establish a new connection: [Errno 111] Connection refused')).\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPConnectionPool(host='10.0.0.222', port=30307): Max retries exceeded with url: /v1/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fcc1269ee20>: Failed to establish a new connection: [Errno 111] Connection refused')).\n",
      "(Jihyun Mun, 1, Department of Linguistics, Seoul National University, Republic of Korea)\n",
      "(Sunhee Kim, 2, Department of French Language Education, Seoul National University, Republic of Korea)\n",
      "(Myeong Ju Kim, 3, Center for Artificial Intelligence in Healthcare, Seoul National University, Republic of Korea)\n",
      "(Jiwon Ryu, 4, Department of Internal Medicine, Seoul National University Bund\n",
      "(speakers, in this, corpus)\n",
      "(CKD patients, with varying, degrees)\n",
      "(delivered, sustained, vowels)\n",
      "(sentence, and paragraph, stimuli)\n",
      "(compared, and analyzed, voice)\n",
      "(phoneme-level pronunciation,prosody, glottal source)\n",
      "(aerodynamic parameters)\n",
      "(there may not be, blood and urine tests, CKD)\n",
      "(CKD affects, variety of bodily systems, respiratory system)\n",
      "(CKD patients, reduced strength and endurance, respiratory muscles)\n",
      "(CKD patients, compromised laryngeal and respiratory muscles)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Finding out, characteristics, CKD voice)\n",
      "(results, how, CKD voice)\n",
      "(speech corpus, different, speech data)\n",
      "(CKD group, stage, voice change)\n",
      "(automatic detection, severity prediction, CKD)\n",
      "(corpus, gathered, voices, CKD patients)\n",
      "(CKD speakers, is, disease)\n",
      "(CKD speakers, is, severity)\n",
      "(CKD speakers, eGFR, severity)\n",
      "---------------------\n",
      "Text: The main goal of this paper is to introduce a novel method for automatically detecting diseases and predicting their severity based on the analysis of CKD voice.To achieve this goal, we developed a corpus of CKD and non-CKD speakers, including their ages, genders, and eGFR levels.The corpus is organized as follows:\n",
      "(Alice, is mother of, Bob)\n",
      "(Alice, is father of, Carol)\n",
      "(Alice, is father of, David)\n",
      "(Alice, is father of, Jane)\n",
      "(Alice, is father of, Peter)\n",
      "(Alice, is father of, Sarah)\n",
      "(Alice, is father of, Susan)\n",
      "(Alice, is father of, Tom)\n",
      "(Alice, is father of, William)\n",
      "(Alice, is mother of, Carol)\n",
      "(Alice, is mother of\n",
      "(vowel, with highest first formant, does not significantly increase first or second harmonics)\n",
      "(vowel, speech, features)\n",
      "(vowel, pitch, features)\n",
      "(vowel, glottal source parameters, MPT)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone)\n",
      "(Samsung Galaxy, series, smartphone\n",
      "(Scarlett Solo Audio Interface, was utilized, to convert microphone signals)\n",
      "(to prevent air puffing, smartphone and microphone were situated)\n",
      "(Speakers were asked to speak naturally)\n",
      "(Authors segmented utterances into separate WAV files)\n",
      "(Praat did this.)\n",
      "(ANALYSIS RESULTS.)\n",
      "(Methods)\n",
      "(, there were fewer non-CKD speakers than CKD speakers,thus authors created new classification for speaker severity based on eGFR.Speakers with an eGFR of more than were considered non,CKD speakers participants,females, males,whereas speakers with an eGFR of less than were considered CKD speakers.For CKD speakers,stage was defined as having an eGFR of or more and less than participants, females,males,and stage as having an eGFR of or more and less than subjects,females,males.)\n",
      "(voices, of, CKD speakers)\n",
      "(voices, of, non-CKD speakers)\n",
      "(voices, of, CKD stage 4 speakers)\n",
      "(voices, of, non-CKD stage 4 speakers)\n",
      "(Bonferroni post hoc test, was additionally conducted.,correlation and regression analyses were conducted to examine relationship between eGFR and each parameter.)\n",
      "(Speech-related features, added new features, such as aerodynamic and glottal source parameters..\n",
      "(Mel-frequency cepstrum MFC, based on linear cosine transform of log power spectrum on nonlinear Mel scale of frequency.)\n",
      "(MFC is made up of coefficients known as\n",
      "(Speaker identification, MFCCs, librosa)\n",
      "(Speaker recognition, log energy, Praat)\n",
      "(Voice quality evaluation, jitter, shimmer, HNR, number of voice breaks, degree of voice breaks, Praat)\n",
      "(Praat, is, divided pitch floor)\n",
      "(Praat, divided pitch floor, Hz)\n",
      "(Praat, divided pitch floor, intervals)\n",
      "(Speech rate, authors measure, total duration)\n",
      "(Articulation rate, authors measure, speech duration)\n",
      "(Pauses, authors measure, speech duration)\n",
      "(Number of pauses, authors measure, pause duration)\n",
      "(Parselmouth, extract features)\n",
      "(Consonantal and vocalic interval standard deviations)\n",
      "(Deltas, authors measure, speech duration)\n",
      "(Varcos,\n",
      "(correlatore, is, speech recognizer)\n",
      "(correlatore, is, Kaldi toolkit)\n",
      "(correlatore, is, AI Hub corpus)\n",
      "(correlatore, is, number of matches)\n",
      "(Vowel Space Area, Vowel Articulatory Index, Formant Centralized Ratio)\n",
      "(Vowel Space Area, Vowel Articulatory Index, Formant Centralized Ratio)\n",
      "(Vowel Space Area, Vowel Articulatory Index, Formant Centralized Ratio)\n",
      "(Vowel Space Area, Vowel Articulatory Index, Formant Centralized Ratio)\n",
      "(Vowel Space Area, Vowel Articulatory Index, Formant Centralized Ratio)\n",
      "(Vowel Space Area, Vowel Articulatory Index, Form\n",
      "(these features, are extracted)\n",
      "(Aerodynamic feature, objective measurement, of effectiveness, of respiratory mechanism, during phonation)\n",
      "(Praat, used to extract, MPT)\n",
      "(Glottal source parameters, term, glottal source refers to)\n",
      "(Authors suggest incorporating, parameters, relating to glottal flow, because)\n",
      "(It can result, in vocal cord, edema.)\n",
      "(H1, H2, A1)\n",
      "(H1, A2, A3)\n",
      "(A1, A2, A3)\n",
      "(parameters, measured, referred to as)\n",
      "(vowel and sentence, measured, referred to as)\n",
      "(voice quality, HNR, value)\n",
      "(voice quality, jitter, shimmer)\n",
      "(voice quality, CKD, non-CKD)\n",
      "(voice quality, CKD, severity)\n",
      "(voice quality, HNR, value)\n",
      "(voice quality, jitter, shimmer)\n",
      "(voice quality, CKD, non-CKD)\n",
      "(voice quality\n",
      "(CKD groups, showed, higher pitch)\n",
      "(CKD groups, showed, longer speech duration)\n",
      "(CKD groups, showed, lower articulation rate)\n",
      "(CKD groups, showed, higher pitch)\n",
      "(CKD groups, showed, longer speech duration)\n",
      "(CKD groups, showed, lower articulation rate)\n",
      "(CKD groups, showed, higher pitch)\n",
      "(CKD groups, showed, longer speech duration)\n",
      "(CKD groups, showed, lower articulation rate)\n",
      "(CKD groups, showed, higher pitch)\n",
      "(authors, performed, regression analysis)\n",
      "(eGFR, has, impact on dependent variables)\n",
      "(aerodynamic,glottal source, phoneme-level pronunciation)\n",
      "(prosody,F0, gender)\n",
      "(results, revealed, F0)\n",
      "(it, suggests, gender)\n",
      "(non-CKD, vs., CKD)\n",
      "(authors, should, examine)\n",
      "(authors, different, features)\n",
      "(authors, CKD, speech)\n",
      "(authors, stage, publications)\n",
      "(authors, non-CKD, vs.)\n",
      "(authors, CKD, stage)\n",
      "(authors, stage, publications)\n",
      "(authors, non-CKD, vs.)\n",
      "(authors, CKD, stage)\n",
      "(SVM, is, classifier)\n",
      "(SVM, works, better)\n",
      "(SVM, with, highdimensional)\n",
      "(SVM, with, small)\n",
      "(SVM, with, datasets)\n",
      "(SVM, with, high-dimensional)\n",
      "(SVM, with, small)\n",
      "(SVM, with, datasets)\n",
      "(SVM, with, high-dimensional)\n",
      "(SVM, with, small)\n",
      "(SVM,\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(-, Nov. Kwon., and Han., Diagnosis and screening of chronic kidney disease)\n",
      "(-, Effect of chronic renal failure on voice an acoustic and aerodynamic analysis)\n",
      "(-, Voice in Chronic Renal Failure)\n",
      "(Jung.,Ryu.,Park.,Chung.,Ryu., and Kim.,,Voice change in end-stage renal disease hoarseness and objective acoustic parameters,Journal of Voice,vol.,no.,pp.-,July.)\n",
      "(Zaky.,Mamdouh.,Esmat.,and Khalaf.,,Voice problem in patient with chronic renal failure, Egyptian Journal of Otolaryngology,vol.,no.,pp.-,Nov.)\n",
      "(Mudawwar.,Alan.,Sarieddine.,Turfe., and Hamdan.,,Effect of renal failure on voice,ENT Ear,Nose Thro\n",
      "(H1, Measure, Speech Sciences)\n",
      "(Lee.,Kim.,Sim.,Nam.,Choi.,and Park.)\n",
      "(Auditory-perceptual evaluation of speech)\n",
      "(Nov., IBM Corp., released)\n",
      "(IBM SPSS Statistics for Windows, Version)\n",
      "(Armonk,NY IBM Corp Yeo.,Kin.,and Chung.)\n",
      "(Automatic Severity Classification of Korean Dysarthric Speech Using Phoneme, Level Pronunciation Features)\n",
      "(Voiceprints analysis using MFCC and SVM for detecting patients with Parkinsons disease)\n",
      "(Proceedings of 14th python in science\n",
      "(Teixeira.,Oliveira.,and Lopes., Vocal acoustic analysis-jitter,shimmer and hnr parameters,Procedia Technology,vol.,pp.-,Dec..)\n",
      "(Prosody-based measures for automatic severity assessment of dysarthric speech.)\n",
      "(Applied Sciences, Mairano, and Romano, Un confronto tra diverse metriche ritmiche, Correlatore, Schmid., Schwarzenbach, Studer, La dimensione temporale del parlato, Proc.of National AISV Congress, University of Zurich, Collegiengebaude, - February, Torriana, AIHub Homepage, Pove\n",
      "(Skodda., Visser., Schlegel., Vowel articulation in Parkinsons disease, Journal of voice, vol. no., pp. -, July)\n",
      "(Characteristics of vowel space and speech intelligibility in patients with spastic dysarthria, Communication Sciences Disorders, vol. no., pp.,, Sep.)\n",
      "(Maximum phonation time variability and reliability, Journal of Voice, vol. no., pp.-, Oct.)\n",
      "(Kumar.,Bhat.,and Mukhi.,Vowel harmonic amplitude differences)\n",
      "(Lee.,Cho.,Song.,Lee.,Kim.,and Kim., Aging effect)\n",
      "(Keating.,and Esposito.,Linguistic Voice Quality)\n",
      "(He., Zhang., Ren., Sun., Deep, Residual, Learning, for, Image, Recognition)\n",
      "Processing: 2304.04280v1.FrenchMedMCQA__A_French_Multiple_Choice_Question_Answering_Dataset_for___Medical_domain\n",
      "(FrenchMedMCQA, is, French Multiple-Choice Question Answering)\n",
      "(FrenchMedMCQA, questions, 5 possible answers)\n",
      "(FrenchMedMCQA, answers, manual correction)\n",
      "(FrenchMedMCQA, identifier, question, five possible answers, manual correction)\n",
      "(NLP, is, task)\n",
      "(NLP, consists in, answering)\n",
      "(NLP, reading comprehension, skills)\n",
      "(NLP, external sources of knowledge, to reach decent performance)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(French community, has, greatly increased)\n",
      "(French community, has, increased)\n",
      "(French community, has, greatly increased)\n",
      "(French community, has, increased)\n",
      "(French community, has, greatly increased)\n",
      "(French community, has, increased)\n",
      "(French community, has, greatly increased)\n",
      "(French community, has, increased)\n",
      "(French community, has, greatly increased)\n",
      "(French community, has, increased)\n",
      "(French community, has, greatly increased)\n",
      "(French community, has, increased)\n",
      "(French community, has,\n",
      "(Main contributions, paper, concern)\n",
      "(Main contributions, paper, medical field)\n",
      "(Main contributions, paper, state-of-art approach)\n",
      "(Main contributions, paper, first analysis of results)\n",
      "(Main contributions, paper, open corpus)\n",
      "(Main contributions, paper, tools and models)\n",
      "(exams, on, remede1)\n",
      "(exams, website, community)\n",
      "(exams, medicine, pharmacy)\n",
      "(exams, information, news)\n",
      "(exams, job, offers)\n",
      "(exams, forums, students)\n",
      "(exams, professionals, jobs)\n",
      "(exams, single, question)\n",
      "(exams, tokens, answer)\n",
      "(FrenchMedMCQA, is, dataset)\n",
      "(FrenchMedMCQA, is, medical)\n",
      "(FrenchMedMCQA, is, questions)\n",
      "(FrenchMedMCQA, is, answers)\n",
      "(FrenchMedMCQA, is, correct responses)\n",
      "(FrenchMedMCQA, is, per question)\n",
      "(FrenchMedMCQA, is, per answer)\n",
      "(FrenchMedMCQA, is, per domain)\n",
      "(FrenchMedMCQA, is, per domain-specific word)\n",
      "(FrenchMedMCQA, is, per domain-specific word and question)\n",
      "(FrenchMedMCQA, is, per domain-specific word and answer)\n",
      "(\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Gurevych, is used to perform, semantic search)\n",
      "(Gurevych, is used to perform, semantic search using)\n",
      "(Gurevych, is used to perform, semantic search using state-of-art language Transformers library Wolf et al.)\n",
      "(Gurevych, is used to perform, semantic search using state-of-art language Transformers library Wolf et al.)\n",
      "(Gurevych, is used to perform, semantic search using state-of-art language Transformers library Wolf et al.)\n",
      "(Gurevych, is used to perform, semantic search using state-of-\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Authors, firstly, propose)\n",
      "(Authors, propose, to use)\n",
      "(Authors, use, CamemBERT)\n",
      "(Authors, evaluate, two)\n",
      "(Authors, consider, multilingual)\n",
      "(Authors, evaluate, gap)\n",
      "(Authors, evaluate, with)\n",
      "(Authors, consider, XLM-RoBERTa)\n",
      "(Authors, evaluate, performance)\n",
      "(Authors, evaluate, with)\n",
      "(Authors, evaluate, CamemBERT)\n",
      "(Authors, evaluate, SOTA)\n",
      "(Authors, evaluate, QA)\n",
      "(\n",
      "(their, interest, on, several)\n",
      "(NLP, tasks, in, particular)\n",
      "(text generation, comprehension, tasks)\n",
      "(BART, Lewis et al., denoising autoencoder)\n",
      "(BART, Radford et al., GPT)\n",
      "(BART, training, two, stages)\n",
      "(BART, representation, in, paper)\n",
      "(BART, evaluation, in, paper)\n",
      "(BART, representation, in, paper)\n",
      "(each studied, discriminative, generative)\n",
      "(each studied, MCQA, FrenchMedMCQA)\n",
      "(each studied, BM25, FrenchMedBM25)\n",
      "(each studied, semantic search, FrenchMedsemantic search)\n",
      "(each studied, MCQA, BM25)\n",
      "(each studied, semantic search, BM25semantic search)\n",
      "(each studied, MCQA, semantic search)\n",
      "(each studied, semantic search, semantic search)\n",
      "(each studied, MCQA, semantic search, semantic search, EOS)\n",
      "(Concerning outputs,generative model,plain text)\n",
      "(Concerning outputs,discriminative approaches,multi-label problem)\n",
      "(Concerning outputs,classification,inputs into existing combinations)\n",
      "(Concerning outputs,majority of tasks,either on multiclass or binary classification)\n",
      "(Concerning outputs,occasionally,authors will Wiki Wiki MiniLMv2 HAL MiniLMv2 BioBERT V1.)\n",
      "(Concerning outputs,performance,test set using Hamming score and EMR metrics.)\n",
      "(\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Hamming score, EMR, Without Context)\n",
      "(BART-base, EMR, Without Context)\n",
      "(RoBERTa, EMR, Without Context)\n",
      "(BioBERT V1, EMR, Without Context)\n",
      "(without retriever part, EMR, With Context)\n",
      "(with retriever part, EMR, Without Context)\n",
      "(with retri\n",
      "(fact, that, best passage)\n",
      "(XLM-RoBERTa-base, considered, best model)\n",
      "(XLM-RoBERTa-base, obtained, best performance)\n",
      "(XLM-RoBERTa-base, source, depends)\n",
      "(XLM-RoBERTa-base, model, depends)\n",
      "(XLM-RoBERTa-base, pre-trained, models)\n",
      "(XLM-RoBERTa-base, obtained, best performance)\n",
      "(XLM-RoBERTa-\n",
      "(original,open, publicly available)\n",
      "(French, corpus, in medical field)\n",
      "(French, single, answers to questions)\n",
      "(French, multiple, answers to questions)\n",
      "(French, state- art, systems evaluated)\n",
      "(French, language models specialized)\n",
      "(French, English biomedical models applied)\n",
      "(French, current performance)\n",
      "(French, other strategies for retriever module)\n",
      "(French, data representation models for French specialized)\n",
      "(This work, was, financially supported)\n",
      "(Zenidoc, DIETS, ANR)\n",
      "(AGENCE Nationale de la Recherche, ANR)\n",
      "(AIBy4, ANR)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Gao, is, Chinese language model)\n",
      "(Gao, is, machine translation model)\n",
      "(Gao, is, text summarization model)\n",
      "(Domainspecific language model, pretraining, biomedical natural language processing)\n",
      "(Gautier Izacard and Edouard Grave, Leveraging passage retrieval, open domain question answering)\n",
      "(Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Hannaneh Hajishirzi, Unifiedqa Crossing format boundaries with single qa system)\n",
      "(Guokun Lai,Qizhe Xie,Hanxiao Liu,Yiming Yang, and Eduard Hovy)\n",
      "(CamemBERT, tasty, French)\n",
      "(CamemBERT, 58th Annual Meeting, Association for Computational Linguistics)\n",
      "(CamemBERT, tasty, French, 58th Annual Meeting, Association for Computational Linguistics)\n",
      "(Todor Mihaylov, Peter Clark, Tushar Khot, Ashish Sabharwal)\n",
      "(Alec Radford,Jeff Wu,Rewon Child,David Luan, Dario Amodei,and Ilya Sutskever,are,language models)\n",
      "(Nils Reimers,and Iryna Gurevych,sentence embeddings using siamese bertnetworks)\n",
      "(Matthew Richardson,Christopher.Burges,and Erin Renshaw,MCTest challenge dataset for open-domain machine comprehension of text)\n",
      "(In Proceedings of Conference on\n",
      "(Wenhui Wang, is, author)\n",
      "(Wenhui Wang, is, author, born in)\n",
      "(Wenhui Wang, born in, 1950s)\n",
      "(Minilmv2, is, multi-head selfattention relation distillation)\n",
      "(Minilmv2, transformers, State-of-art)\n",
      "(Minilmv2, natural language processing, Huggingfaces)\n",
      "Processing: 2305.06801v1.Detecting_Idiomatic_Multiword_Expressions_in_Clinical_Terminology_using___Definition_Based_Representation_Learning\n",
      "(Detecting, Idiomatic, Multiword Expressions)\n",
      "(Clinical, Terminology, Idiomaticity)\n",
      "(Detecting, Idiomatic, Multiword Expressions)\n",
      "(Clinical, Terminology, Idiomaticity)\n",
      "(corpus-free idiomaticity estimation, helps, ontology translators)\n",
      "(Neves et al., million entities)\n",
      "(Schulz and Klein, full coverage)\n",
      "(Macary, Auwers)\n",
      "(MWE, is, translation)\n",
      "(MWE, is, translation difficulty)\n",
      "(MWE, is, idiomatic)\n",
      "(MWE, is, idiomatic meaning)\n",
      "(MWE, is, idiomatic meaning, translation)\n",
      "(MWE, is, idiomatic meaning, translation difficulty)\n",
      "(MWE, is, idiomatic meaning, idiomatic)\n",
      "(MWE, is, idiomatic meaning,\n",
      "(Ramisch et al., have been presented, Kafando et al., Zeng and Bhat)\n",
      "(Ramisch et al., have been presented, Kafando et al., Zeng and Bhat)\n",
      "(Ramisch et al., have been presented, Kafando et al., Zeng and Bhat)\n",
      "(Ramisch et al., have been presented, Kafando et al., Zeng and Bhat)\n",
      "(Ramisch et al., have been presented, Kafando et al., Zeng and Bhat)\n",
      "(Ramisch et\n",
      "(1MWE, is, MWE)\n",
      "(1MWE, is, MWE, W1)\n",
      "(1MWE, W1, is, MWE, Wn)\n",
      "(1MWE, W1, is, MWE, Wn, Ri)\n",
      "(1MWE, Wn, Ri, MWE)\n",
      "(1MWE, Wn, Ri, MWE, W1)\n",
      "(1MWE, Wn, Ri, MWE\n",
      "(SemReprOf, is, semantic model)\n",
      "(SemReprOf, is, Transformer Mean Pooling pipeline)\n",
      "(SemReprOf, is, W1.Wn)\n",
      "(SemReprOf, is, To isolate effect of these interactions)\n",
      "(SemReprOf, is, To determine optimal weights)\n",
      "(SemReprOf, is, To explain low self-explainability scores)\n",
      "(SemReprOf, is, To determine optimal weights in Appendix)\n",
      "(SemReprOf, is, To explain low self-explainability scores\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "---------------------\n",
      "Text: The authors aim to investigate the relationship between the complexity of a sentence and its meaning.To achieve this,they will analyze the relationship between the number of words, the number of prepositions, and the complexity of sentences.\n",
      "Triplets:\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "---------------------\n",
      "Text: The authors aim to investigate the relationship between the complexity of a sentence and its\n",
      "(Authors, hypothesize, definition-based pretraining)\n",
      "(Authors, propose, analysis)\n",
      "(Authors, set out, evaluate)\n",
      "(Authors, compare, results)\n",
      "(Authors, evaluate, benefits)\n",
      "(Authors, compare, two strong alternatives)\n",
      "(Authors, evaluate, CODER)\n",
      "(Authors, evaluate, SapBERT)\n",
      "(Authors, evaluate, BioLORD)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(BioLORD, has, large)\n",
      "(BioLORD, has, area)\n",
      "(BioLORD, has, 95th percentile)\n",
      "(BioLORD, has, recall)\n",
      "(BioLORD, has, precision)\n",
      "(BioLORD, has, F1)\n",
      "(BioLORD, has, AUC)\n",
      "(BioLORD, has, precision@95\n",
      "(This, enables, us, to, estimate, full, distribution, with, population, counts, see.)\n",
      "(means.vs.,indicating, that, our, self-explainability, score, is, indeed, significantly, lower, for, idiomatic, MWEs, than, non-idiomatic, ones.)\n",
      "(about.of, MWEs, in, our, dataset, appeared, idiomatic, or, semi-idiomatic, in, nature.)\n",
      "(To, evaluate, how, effectively, our, self-explainability, score, can, help, identifying, idiomatic,\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(results, authors report, lowest self-explainability scores)\n",
      "(BioLORD, features, higher quality)\n",
      "(BioLORD, weights, specialize idiomatic MWEs)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(Authors, can, further this impression)\n",
      "(BioLORD, is, semantic model)\n",
      "(BioLORD, trained, definition-based)\n",
      "(BioLORD, in, biomedical domain)\n",
      "(BioLORD, out, self-explainability score)\n",
      "(BioLORD, in, challenging MWEs)\n",
      "(BioLORD, out, half of self-explainability score outliers)\n",
      "(It, worth, note)\n",
      "(It, is, worth)\n",
      "(It, note, about)\n",
      "(Tom Auwers, Snomed ct, dutch and french)\n",
      "(Olivier Bodenreider, language system, UMLS integrating biomedical terminology)\n",
      "(John Mervyn Evjen, highlighting difficulties in idiomatic translation)\n",
      "(Marcos Garcia, Tiago Kramer Vieira, Carolina Scarton, Marco Idiart, and Aline Villavicencio, Probing for idiomaticity in vector space models)\n",
      "(Rodrique, Kafando, Rmy)\n",
      "(Rmy, Decoupes, Sarah)\n",
      "(Sarah, Valentin, Lucile)\n",
      "(Lucile, Sautot, Maguelonne)\n",
      "(Maguelonne, Teisseire, Mathieu)\n",
      "(Francois, Macary, exemplar)\n",
      "(Macary, first release, snomed ct)\n",
      "(Macary, exemplar, collaboration)\n",
      "(Macary, first release, snomed ct)\n",
      "(Macary, exemplar, collaboration)\n",
      "(Giorgio Maria Di Nunzio,Federica Vezzani,Christel Gerardin)\n",
      "(Giorgio Maria Di Nunzio,Federica Vezzani,Rachel Bawden)\n",
      "(Giorgio Maria Di Nunzio,Federica Vezzani,Darryl Johan Estrada)\n",
      "(Giorgio Maria Di Nunzio,Federica Vezzani,Salvador Lima-\n",
      "(Ziheng Zeng, is, idiomatic expression identification)\n",
      "(Ziheng Zeng, using, semantic compatibility)\n",
      "(Ziheng Zeng, and, Suma Bhat, for, idiomatic expression identification)\n",
      "(R1, is, vector representation of MWE)\n",
      "(R2, is, vector representation of MWE)\n",
      "(R1, weighted average, cosine similarity between vector representation of MWE and weighted average)\n",
      "(R2, weighted average, cosine similarity between vector representation of MWE and weighted average)\n",
      "Triplets:\n",
      "(R1, is, vector representation of MWE)\n",
      "(R2, is, vector representation of MWE)\n",
      "(R1, weighted average, cosine similarity between vector representation of MWE and weighted average)\n",
      "(R2, weighted average, cosine similarity between vector representation of MWE\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(R1, R2, R3)\n",
      "(joint session, which, this paper)\n",
      "(joint session, which, this paper was submitted to)\n",
      "(joint session, which, this paper was submitted to, enabled)\n",
      "Processing: 2306.00665v1.Automatic_Glossary_of_Clinical_Terminology__a_Large_Scale_Dictionary_of___Biomedical_Definitions_Generated_from_Ontological_Knowledge\n",
      "(AGCT, is, large-scale biomedical dictionary)\n",
      "(AGCT, is, comprehensive biomedical ontology)\n",
      "(AGCT, is, NLP-evaluated subset)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Tsatsaronis et al.,, bridge gap between)\n",
      "(Tsatsaronis et al.,, textual definitions)\n",
      "(Tsatsaronis et al.,, biomedical concepts)\n",
      "---------------------\n",
      "Text: The main objective of this study is to evaluate the effectiveness of using machine learning algorithms in predicting the price of a product based on its features.\n",
      "Triplets:\n",
      "(The main objective,, of this study)\n",
      "(The main objective,, of predicting the price)\n",
      "(The main objective,, of using machine learning algorithms)\n",
      "---------------------\n",
      "Text: The main objective of this study is\n",
      "(GPT, is, machine learning model)\n",
      "(GPT, generated, medical concept definition)\n",
      "(GPT, summarized, verbalization of SnomedCT relationship)\n",
      "(GPT, precise, instructions for generation of biomedical concept definition)\n",
      "(GPT, is, its)\n",
      "(GPT, is, its data)\n",
      "(GPT, is, its data curation)\n",
      "(GPT, is, its data curation for every token generated by model,four times more tokens were provided to model in its prompt,on average. hypothesis was that this saturation of information should ensure that generated definitions are well-informed and therefore factual,coupled with already impressive biomedical knowledge of GPTKung et al.,Gilson et al.\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Insight, is, weakly correlated)\n",
      "(Factuality, is, moderately correlated)\n",
      "(Fluency, is, strongly correlated)\n",
      "(R2, is, moderately correlated)\n",
      "(Insight, R2, moderately correlated)\n",
      "(Factuality, R2, strongly correlated)\n",
      "(Fluency, R2, strongly correlated)\n",
      "(R2, Insight, moderately correlated)\n",
      "(R\n",
      "(Factuality, criticality, Fluency)\n",
      "(Factuality, importance, Fluency)\n",
      "(Factuality, relevance, Fluency)\n",
      "(Fluency, importance, Relevance)\n",
      "(Fluency, relevance, Relevance)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(SnomedCT, is, concept)\n",
      "(SnomedCT, factuality, high)\n",
      "(SnomedCT, insight, medical)\n",
      "(SnomedCT, fluency, medical)\n",
      "---------------------\n",
      "Text: The main goal of this paper is to introduce a new dataset of high-quality biomedical definitions,which can be used for training retrieval models in biomedical NLP tasks.\n",
      "Triplets:\n",
      "(SnomedCT, is, concept)\n",
      "(SnomedCT, fact\n",
      "(dataset, suitable for, pre-training tasks)\n",
      "(dataset, for, biomedical retrieval models)\n",
      "(dataset, for, low-rank finetuning)\n",
      "(SnomedCT, does not, cover)\n",
      "(SnomedCT, all possible, relationships)\n",
      "(SnomedCT, biasing, output)\n",
      "(SnomedCT, authors, do not)\n",
      "(SnomedCT, ethical, concern)\n",
      "(SnomedCT, guidelines, outline)\n",
      "(SnomedCT, more, relevant, metrics)\n",
      "(SnomedCT, less, extensive, QA)\n",
      "(SnomedCT, releasing, dataset)\n",
      "(SnomedCT, preventing, unnecessary)\n",
      "(SnomedCT, possibly,\n",
      "(This work, would, not, have, been, possible, without, joint, financial, support, Vlaams, Agentschap, Innoveren, Ondernemen, VLAIO, and, RADar, innovation, center, of, AZ, Delta, hospital, group.)\n",
      "(Amanda, Joseph, Kushniruk, Borycki)\n",
      "(Tiffany.Kung, Morgan Cheatham, Arielle Medenilla)\n",
      "(Tiffany.Kung, is, Morgan Cheatham)\n",
      "(Tiffany.Kung, is, Arielle Medenilla)\n",
      "(Tiffany.Kung, is, Czarina Sillos)\n",
      "(Tiffany.Kung, is, Lorie De Leon)\n",
      "(Tiffany.Kung, is, Camille Elepao)\n",
      "(Tiffany\n",
      "(Long Ouyang,Jeff Wu,Xu Jiang)\n",
      "(Diogo Almeida,Carroll.Wainwright,Pamela Mishkin)\n",
      "(Alex Ray,John Schulman,Jacob Hilton)\n",
      "(Fraser Kelton,Luke Miller,Paul Christiano)\n",
      "(Jan Leike,Ryan Lowe)\n",
      "(Franois Remy, Kris Demuynck, Thomas Demeester)\n",
      "(Stefan Schulz, Gunnar.Klein.Snomed ct, advances in)\n",
      "(Stefan Schulz, Gunnar.Klein.Snomed ct, advances in concept mapping,retrieval,and ontological foundations)\n",
      "(Stefan Schulz, Gunnar.Klein.Snomed ct, advances in concept mapping,retrieval,and ontological foundations)\n",
      "(System Assistant, is, large language model)\n",
      "(System Assistant, specialized in, biomedical and clinical knowledge)\n",
      "(System Assistant, can answer questions about, diseases,medications,and more)\n",
      "(SnomedCT, is, medical ontology)\n",
      "(SnomedCT, standardized vocabulary, of medical terms)\n",
      "(SnomedCT, reliable,and can be used to classify diseases and medications)\n",
      "(User, talks about, medical concepts)\n",
      "(User, does, SnomedCT)\n",
      "(User, SnomedCT, says)\n",
      "(User, SnomedCT, about)\n",
      "(User, SnomedCT, following)\n",
      "(User, SnomedCT, about medical concept)\n",
      "(User, SnomedCT, following medical concept)\n",
      "(User, SnomedCT, about medical concept, details)\n",
      "(User, SnomedCT, about medical concept, unimportant details)\n",
      "(Along with, our, entire, dataset)\n",
      "(HuggingFace, is, subject to)\n",
      "(HuggingFace, is, subject to both)\n",
      "(HuggingFace, is, subject to both SnomedCT and OpenAI API agreements)\n",
      "Processing: 2307.07051v1.Making_the_Most_Out_of_the_Limited_Context_Length__Predictive_Power___Varies_with_Clinical_Note_Type_and_Note_Section\n",
      "(MIMIC-III, is, large)\n",
      "(MIMIC-III, is, nursing notes)\n",
      "(MIMIC-III, is, discharge notes)\n",
      "(EHR, enable, language model)\n",
      "(EHR, predict, patient outcomes)\n",
      "(EHR, subsample, text sections)\n",
      "(EHR, subsample, high predictive power)\n",
      "(EHR, subsample, text sections, high predictive power)\n",
      "(Empirically, authors explore, distribution of predictive power over clinical note types and sections)\n",
      "(Empirically, authors find, predictive power distribution is different between nursing notes and discharge notes)\n",
      "(Empirically, authors find, uniform within nursing notes)\n",
      "(Empirically, authors find, effect of combining sections from different types of notes improves performance when context size is large)\n",
      "(Empirically, authors find, harms performance when context size is small)\n",
      "(Empirically, authors find, code is publicly available on GitHub)\n",
      "(Existing methods, are based on, BERT-based model)\n",
      "(Existing methods, are based on, domain knowledge)\n",
      "(Existing methods, explore data-driven, without assumptions)\n",
      "(Existing methods, explore data-driven, without assumptions)\n",
      "(Instead, of, subsampling)\n",
      "(Huang, et al., propose, to)\n",
      "(model, feed, everything)\n",
      "(one, maximum, context, length)\n",
      "(at, time, aggregation)\n",
      "(output, probabilities, from, each, subsequence)\n",
      "(cost, scales, with, aggregated, sequence)\n",
      "(expensive, for, records, with, long, clinical)\n",
      "(long, clinical, notes, expensive)\n",
      "(input, find, one, information-rich)\n",
      "(segment, as, input, for, prediction)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Authors, hypothesize, that)\n",
      "(Authors, focus on, parameterized)\n",
      "(Authors, finetune, two)\n",
      "(Authors, predict, probability)\n",
      "(Authors, enable, input, up)\n",
      "(Authors, predict, re-admission)\n",
      "(Authors, predict, within)\n",
      "(Authors, predict, days)\n",
      "(Authors, predict, hospital)\n",
      "(Authors, predict, within)\n",
      "(database, Johnson et al., de-identified)\n",
      "(database, Johnson et al., admission records)\n",
      "(database, Johnson et al., train.validation, test)\n",
      "(database, Johnson et al., lp, lp)\n",
      "(database, Johnson et al., shifted window, shifted window)\n",
      "(database, Johnson et al., shifted window, shifted window, lp)\n",
      "(database, Johnson\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Nursing notes, is, predictive power)\n",
      "(Nursing notes, is, sections of text)\n",
      "(Nursing notes, describes, patient information)\n",
      "(Nursing notes, describes, patient information, suggestions for patients)\n",
      "(Nursing notes, produce, decent)\n",
      "(Nursing notes, are, AUC ROC scores)\n",
      "(Nursing notes, first, orange line)\n",
      "(Nursing notes, second, green line)\n",
      "(Nursing notes, third, bars)\n",
      "(ClinicalBERT, AUC ROC, clinical note combinations)\n",
      "(ClinicalLongformer, AUC ROC, clinical note combinations)\n",
      "(ClinicalBERT, performance, clinical note combinations)\n",
      "(ClinicalLongformer, performance, clinical note combinations)\n",
      "(ClinicalBERT, AUC ROC, clinical note combinations, error bars represent confidence intervals)\n",
      "(ClinicalLongformer, AUC ROC, clinical note combinations, error bars represent confidence intervals)\n",
      "(types of clinical notes, clinicalbert, clinicallongformer)\n",
      "(types of clinical notes, clinicalbert, clinicallongformer)\n",
      "(types of clinical notes, clinicalbert, clinicallongformer)\n",
      "(Clinical BERT, is, model)\n",
      "(Clinical BERT, is, finetuned)\n",
      "(Clinical BERT, is, combined notes)\n",
      "(Clinical BERT, is, baseline)\n",
      "(Clinical BERT, is, discharge notes)\n",
      "(Clinical BERT, is, orange notes)\n",
      "(Clinical BERT, is, green notes)\n",
      "(Clinical BERT,\n",
      "(findings, suggest, that)\n",
      "(findings, suggest, high predictive)\n",
      "(findings, vary, across)\n",
      "(findings, vary, text types)\n",
      "(findings, vary, note sections)\n",
      "(ClinicalBERT, is, future directions)\n",
      "(ClinicalLongformer, is, future directions)\n",
      "(ClinicalLongformer, subsection.indicate, future directions)\n",
      "(ClinicalLongformer, subsection.indicate, subsection.indicate)\n",
      "(ClinicalLongformer, subsection.indicate, subsection.indicate)\n",
      "(ClinicalLongformer, subsection.indicate, subsection.indicate)\n",
      "(ClinicalLongformer, subsection.indicate, subsection.indicate)\n",
      "(ClinicalLongformer, subsection.indicate, subsection.ind\n",
      "(Iz Beltagy, Matthew.Peters, and Arman Cohan, longformer, long-document transformer.)\n",
      "(Sajad Darabi, Mohammad Kachuee, Shayan Fazeli, Majid Sarrafzadeh)\n",
      "(Alistair.Johnson, Tom.Pollard, Lu Shen, Li wei.Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger.Mark.Mimic-iii, freely accessible)\n",
      "(Nischay Bikram Thapa,Sattar Seifollahi,Sona Taheri)\n",
      "(Language model classifier, aligns better, physician word sensitivity)\n",
      "(Language model classifier, aligns better, xgboost on readmission prediction)\n",
      "(Language model classifier, cleans datasets, removes de-identification patterns)\n",
      "Processing: 2307.07513v1.An_empirical_study_of_using_radiology_reports_and_images_to_improve_ICU___mortality_prediction\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Survival, predicted, ICU mortality)\n",
      "(Survival, predicted, ICU mortality)\n",
      "(Survival, predicted, ICU mortality)\n",
      "(Survival, predicted, ICU mortality)\n",
      "---------------------\n",
      "Text: The rapid development of artificial intelligence (AI) has led to significant advancements in various fields, including healthcare.AI-powered diagnostics have improved the accuracy of medical imaging, enabling more accurate diagnosis of diseases.\n",
      "Triplets:\n",
      "(Diagnostics, AI-\n",
      "(Results, model, achieves)\n",
      "(Results, achieves, average)\n",
      "(Results, model, C-index)\n",
      "(Results, model, SAPS-II features)\n",
      "(Results, model, pre-defined labels)\n",
      "(Results, model, image features)\n",
      "(Deep learning, Multimodal fusion, Predictive ICU scoring systems)\n",
      "(Mortality prediction, Deep learning, Multimodal fusion)\n",
      "(Mortality prediction, Deep learning, Predictive ICU scoring systems)\n",
      "(Mortality prediction, Deep learning, Multimodal fusion)\n",
      "(Mortality prediction, Deep learning, Predictive ICU scoring systems)\n",
      "(Mortality prediction, Deep learning, Multimodal fusion)\n",
      "(recent development, of, machine learning)\n",
      "(recent development, offers, potential)\n",
      "(recent development, used, only)\n",
      "(recent development, made, improvements)\n",
      "(recent development, compared, with)\n",
      "(recent development, made, without)\n",
      "(recent development, compared, with current)\n",
      "(recent development, made, without)\n",
      "(recent development, focused, on)\n",
      "(recent development, made, without)\n",
      "(recent development, compared, with)\n",
      "(recent development, made, without)\n",
      "(recent development, compared, with current)\n",
      "(recent development, made, without)\n",
      "(recent development, focused, on)\n",
      "(recent development, made, without)\n",
      "(recent development, compared, with)\n",
      "(recent development, made, without)\n",
      "(recent development, focused, on)\n",
      "(recent development, made, without\n",
      "(, practice, modern medicine)\n",
      "(, relies, on)\n",
      "(, multimodal, information)\n",
      "(, fusion, strategies)\n",
      "(, early, fusion)\n",
      "(, late, fusion)\n",
      "(, joint, fusion)\n",
      "(, loss, during)\n",
      "(, survival, analysis)\n",
      "(, text, and)\n",
      "(, images, in)\n",
      "(, survival, analysis)\n",
      "(, insufficiently, studied)\n",
      "(Authors, therefore, sought, to overcome, these limitations, by incorporating, potentials, of, natural language processing, NLP, and medical image analysis, to identify, hidden features, of critical illness, among ICU patients, in radiology reports, and chest X-rays, and investigate, deep learning models, that may provide, superior discrimination, of ICU mortality predictions, compared to traditional, machine learning models.)\n",
      "(radiology imaging, was studied, first hours)\n",
      "(radiology imaging, was studied, ICU mortality)\n",
      "(radiology imaging, was studied, SAPS-II)\n",
      "(radiology imaging, was studied, MIMIC-IV)\n",
      "(radiology imaging, was studied, multimodal)\n",
      "(radiology imaging, was studied, unimodal)\n",
      "(radiology imaging, was studied, SAPS-II, MIMIC-IV)\n",
      "(Task Authors, first formulate, survival analysis task)\n",
      "(Authors, have patients, xi)\n",
      "(Authors, have patients, xi, Rd)\n",
      "(Authors, have patients, xi, Rd, Ti)\n",
      "(Authors, have patients, xi, Rd, Ti, Ci)\n",
      "(Authors, use, Cox model)\n",
      "(Authors, use, Cox model, S0)\n",
      "(Authors\n",
      "(Note, is, patient)\n",
      "(Note, patient, has)\n",
      "(Note, has, survival)\n",
      "(Note, survival, function)\n",
      "(Note, function, Cox)\n",
      "(Note, Cox, model)\n",
      "(Note, model, DeepSurv)\n",
      "(Note, DeepSurv, model)\n",
      "(Note, DeepSurv, model, has)\n",
      "(Note, has, survival)\n",
      "(Note, survival\n",
      "(This, includes,but is not limited to)\n",
      "(This, includes,but is not limited to)\n",
      "(This, includes,but is not limited to)\n",
      "(xi Avg, DNNimg, ximg)\n",
      "(DNNtext, xtext, xsaps)\n",
      "(GCN, Fig., Multimodal)\n",
      "(Patient, has, medical condition)\n",
      "(Patient, has, chronic disease)\n",
      "(Patient, has, admission type)\n",
      "---------------------\n",
      "Text: The aim of this study was to evaluate the effectiveness of a mobile app designed to improve sleep quality in adults.The app, called \"Sleeping Soundly,\" uses a combination of AI-based algorithms and personalized sleep recommendations to help users achieve better sleep quality.The study included a total of participants, who were divided into two groups: a control group and\n",
      "(Atelectasis, Cardiomegaly, Consolidation)\n",
      "(Enlarged Cardiomediastinum, Fracture, Lung lesion)\n",
      "(Lung opacity, Pleural effusion, Pneumonia)\n",
      "(Pneumothorax, Support devices, Normal)\n",
      "(Transformer-based features, second set of features, BERT model)\n",
      "(Transformer-based features, second set of features, BERT model, pre-training on large-scale biomedical and clinical text corpora)\n",
      "(Transformer-based features, second set of features, BERT model, applying average pooling over token embeddings)\n",
      "(Disease finding, is, correlated)\n",
      "(Disease finding, is, connected to)\n",
      "(Disease finding, is, influenced by)\n",
      "(GCN, updates, node representations)\n",
      "(GCN, calculates, D1 AD1)\n",
      "(GCN, adds, self-connections)\n",
      "(GCN, expresses, graph convolution)\n",
      "(GCN, learns, Hl ReLu AH0W b0 softmax AH1W b1)\n",
      "(GCN, updates, trainable layer-specific weights matrix)\n",
      "(GCN, extracts, image features)\n",
      "(Study population, patient selection, C-index)\n",
      "(Study population, patient selection, Ls)\n",
      "(Study population, patient selection, dj)\n",
      "(Study population, patient selection, otherwise)\n",
      "(Study population, patient selection, otherwise, dj)\n",
      "(Study population, patient selection, otherwise, Ls)\n",
      "(Study population, patient selection, otherwise, dj, Ls)\n",
      "(Study population, patient selection, otherwise, dj, Ls\n",
      "(Intuitively, C-index measures extent to which model can assign logical risk scores.)\n",
      "(An individual with shorter time-to-event should have higher risk score than those with longer time-to-event.)\n",
      "(C-index assigns random model.)\n",
      "(MLP layer for SAPS-II risk factors takes an input of dimensions,and fully connects to output dimensions.)\n",
      "(MLP layer for labels features fully connects,dimension inputs to,dimension outputs.)\n",
      "(MLP layer, fully connects, dimension inputs)\n",
      "(MLP layer, fully connects, dimension outputs)\n",
      "(dropout rate, learning rate, with Adam optimizer)\n",
      "(dropout rate, learning rate, with Adam optimizer)\n",
      "(dropout rate, learning rate, with Adam optimizer)\n",
      "(dropout rate, learning rate, with Adam optimizer)\n",
      "(dropout rate, learning rate, with Adam optimizer)\n",
      "(dropout rate, learning rate, with Adam optimizer)\n",
      "(dropout rate, learning rate,\n",
      "(text embeddings, are extracted, using)\n",
      "(BlueBERT, pre-trained, PubMed abstracts and MIMIC-III notes)\n",
      "(BlueBERT, pre-trained, 1982)\n",
      "(BlueBERT, pre-trained, Intel Core i9-9960X cores processor and NVIDIA Quadro RTX GPU)\n",
      "(Authors, compare, baseline, ICU)\n",
      "(Authors, compare, models, four)\n",
      "(Authors, compare, features, SAPS-II)\n",
      "(Authors, compare, features, SAPS-II, GCN)\n",
      "(Authors, compare, features, SAPS-II, GCN, Image)\n",
      "(Authors, compare, multimodal, SAPS-II, risk factors)\n",
      "(Authors, compare, multimodal, SAPS-II, risk factors, early)\n",
      "(Authors, compare, multimodal, SAPS-II, risk\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Patient, has, X-ray abnormalities)\n",
      "(Patient, has, normal chest X-ray)\n",
      "(Patient, has, abnormal chest X-ray)\n",
      "---------------------\n",
      "Text: The model learns to predict the probability of a patient having a specific condition based on their medical records.\n",
      "Triplets:\n",
      "(Patient, has, specific condition)\n",
      "(Patient, has, no specific condition)\n",
      "(Patient, has, other condition)\n",
      "(transformer features, outperforms, model)\n",
      "(GCN features, outperforms, model)\n",
      "(transformer features, does not, contribute to)\n",
      "(GCN features, does not, contribute to)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(C-index, SAPS-II, error analysis)\n",
      "(0.8, 9, 0.01)\n",
      "(0.7, 11, 0.02)\n",
      "(0.6, 13, 0.03)\n",
      "(0.5, 15, 0.04)\n",
      "(0.4, 17, 0.05)\n",
      "(0.3, 19, 0.06)\n",
      "(0.2, 21, 0.07)\n",
      "(0.1, 23, 0.08)\n",
      "(0.0, 25, 0.09)\n",
      "(Patient, has, lung opacity)\n",
      "(Patient, has, abnormal chest x-ray)\n",
      "(Patient, has, normal chest x-ray)\n",
      "(Patient, has, no chest x-ray)\n",
      "(In this paper, authors propose, deep learning method that combines text and image features, to improve ICU mortality prediction. Experiments on MIMIC-IV dataset show that our multimodal features model using SAPS-II risk factors and early fusion of text and X-ray image features obtains superior average C-index than several baselines. This demonstrates that additional information provided by multimodal features can improve ICU mortality prediction performance. Authors investigate whether deep learning methods are more powerful than traditional machine learning methods in\n",
      "(There, are, several)\n",
      "(limitations, to, this, work)\n",
      "(First, authors, use, fusion, strategy)\n",
      "(similar, to, early, fusion)\n",
      "(parameters, of, them, are, not, updated)\n",
      "(Future, authors, plan, to, use, joint, fusion)\n",
      "(propagate, loss, back, to, feature, extraction, modules)\n",
      "(improved, representation, learning, performance)\n",
      "(Domain, knowledge, graph, will, explore)\n",
      "(other, ways, of, incorporating, knowledge, graph)\n",
      "(Longitudinal\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(Alice, is mother of, Bob)\n",
      "(Philz, is, coffee shop)\n",
      "(Philz, founded in, Berkeley)\n",
      "(Philz, founded in, 1982)\n",
      "(A1, SAPS-II, physiological measurements)\n",
      "(A1, PaO2, FiO2)\n",
      "(A1, mm Hg, Blood urea nitrogen)\n",
      "(A1, mL, Urine output)\n",
      "(A1, mEq, Sodium)\n",
      "(A1, x103, White blood count)\n",
      "(A1, x103, Bilirubin)\n",
      "(A1, x103, Filtration rate)\n",
      "(A1, x103, Cardiac index)\n",
      "(A1, x103, Mean arterial pressure)\n",
      "(A1, x103,\n",
      "(Lipshutz.,Feiner.,Grimes.,Gropper.,Predicting mortality in intensive care unit comparison of university health consortium expected probability of mortality and mortality prediction model iii.Journal Zimmerman.,Kramer.,McNair.,Malila.Acute physiology and chronic health evaluation apache iv hospital mortality assessment for todays critically ill patients.Critical care medicine, Le Gall.,Lemeshow.,Saulnier.new simplified acute physiology score saps ii based on euro\n",
      "(Patient, is, normal)\n",
      "(Patient, has, vascular stents)\n",
      "(Patient, has, tortuous aorta)\n",
      "(right lung, compatible with, components of pleural effusion)\n",
      "(right lung, increasing, pleural effusion)\n",
      "(right lung, postobstructive, consolidation)\n",
      "(Ghassemi.,Pimentel.,Naumann.,Brennan.,Clifton.,Szolovits,Feng.,multivariate timeseries modeling approach to severity of illness assessment and forecasting in icu with sparse,heterogeneous clinical data.,In Proceedings of AAAI Conference on Artificial Intelligence,vol. Zhao.,Chen.,Hou.,Graham.,Li.,Richman.,Thode., Singer.,Duong.,Prediction model and risk scores of icu admission and mortality in covid.,In AMIA Annual Symposium Proceedings,vol.)\n",
      "(Murdoch.,Detsky., inevitable application of big data to health care)\n",
      "(Jama., Ching.,Himmelstein.,Beaulieu-Jones.,Kalinin.,Do., Way.,Ferrero.,Agapow.,Zietz.,Hoffman.,et al.)\n",
      "(Opportunities and obstacles for deep learning in biology and medicine)\n",
      "(Multimodal temporal-clinical note network for mortality prediction)\n",
      "(Liu, Lan, Chen)\n",
      "(Liu, Lan, Chen, Wang)\n",
      "(Liu, Lan, Chen, Yang)\n",
      "(Liu, Lan, Chen, Zhao)\n",
      "(et al., bone age assessment model, multidimensional feature fusion, deep learning)\n",
      "(et al., academic journal, second Bakkali, Ming.Coustaty.Rusinol., visual and textual)\n",
      "(et al., IEEE CVF Conference, computer vision and pattern recognition, workshops, Reda., Khalil., Elmogy., Abou El-Fetouh., Shalaby., Abou ElGhar., Elmaghraby., Ghazal., El-Baz.)\n",
      "(technology in cancer research\n",
      "(Deep learning models, multiple sclerosis, brain lesion patterns)\n",
      "(Deep learning models, user-defined clinical and mri features)\n",
      "(Deep learning models, conversion to multiple sclerosis)\n",
      "(Computer Methods in Biomechanics and Biomedical Engineering, Ford.,Carroll.,Smith.,Scott.,Cassell., Journal of American Medical Informatics Association, Weissman.,Hubbard.,Ungar.,Harhay.,Greene., Himes.,Halpern., MIMICIV., PhysioNet.)\n",
      "(Wang.,Peng.,Lu.,Lu.,Bagheri.,Summers.Chestx-ray8 hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases.In IEEE Conference on Computer Vision and Pattern Recognition CVPR,pp.IEEE Katzman.,Shaham.,Cloninger.,Bates.,Jiang.,Kluger.Deepsurv\n",
      "(Zhang., Wang., Xu., Yu., Yuille., Xu., Deng., Peng., Lu., Mark., Berkowitz., Horng.MIMIC-CXR-JPG, large publicly available database of labeled chest radiographs)\n",
      "(Zhang., Wang., Xu., Yu., Yuille., Xu., Deng., Peng., Lu., Mark., Berkowitz., Horng.MIMIC-CXR-JPG,\n",
      "(Huang.,Liu.,Van Der Maaten.,Weinberger.Densely connected convolutional networks.)\n",
      "(Adam, method, stochastic optimization)\n",
      "(Adam, method, for)\n",
      "(Adam, method, stochastic optimization)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method, for)\n",
      "(Adam, method\n",
      "(Peng.,Yan.,Lu.,et al.)\n",
      "(Goodfellow.,Shlens.,Szegedy.,Explaining and harnessing adversarial examples.,Paschali.,Conjeti.,Navab.,Generalizability vs.robustness investigating medical imaging networks using adversarial examples.,In Medical Image Computing and Computer Assisted InterventionMICCAI 21st International Conference,Granada,Spain,September -,Proceedings,Part pp.Springer Finlayson.,Bowers.,Ito.,Zittrain.,Beam.,Kohane.,Adversarial attacks on medical machine learning.,Science,\n",
      "Triplets:\n",
      "(Goodfellow.,Shlens.,Szegedy.,Explaining and harnessing adversarial\n",
      "Documents added in: 608.902054309845s\n"
     ]
    }
   ],
   "source": [
    "if s3_fs.exists(persist_path):\n",
    "    start = time.time()\n",
    "    print(f'Loading index from {persist_path}')\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=persist_path, fs=s3_fs)\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context=storage_context, \n",
    "                                    service_context=service_context, \n",
    "                                    max_triplets_per_chunk=2,\n",
    "                                    show_progress = True)\n",
    "    ## add documents to index\n",
    "    for d in documents:\n",
    "        file_name = pathlib.Path(d.id_).name\n",
    "        print(f'Processing: {file_name}')\n",
    "        #index the document: extract triples and inseart into the KG graph\n",
    "        index.insert(document = d, show_progress = True)\n",
    "        #move the file to the processed folder\n",
    "        #in_file_name = f'{TXT_BASE}/{file_name}'\n",
    "        #processed_file_name = f'{PROCESSED_TXT_BASE}/{file_name}'\n",
    "        #pathlib.Path(in_file_name).rename(processed_file_name)\n",
    "        #index is modified after each doc\n",
    "        save_pyvis_network_graph(index, file_name)\n",
    "        index.storage_context.persist(persist_dir=persist_path, fs=s3_fs)\n",
    "    end = time.time()\n",
    "    print(f\"Documents added in: {end-start}s\")\n",
    "else:\n",
    "    print('No KG Index found, please initialize the Index first.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
