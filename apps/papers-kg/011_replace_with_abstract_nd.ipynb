{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook uses arxiv metadata from https://www.kaggle.com/datasets/Cornell-University/arxiv?resource=download.\n",
    "Current version is 139. Check for a later version before running.\n",
    "'''\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = 'ArxivHealthcareNLP'\n",
    "#CORPUS = 'arxiv_cl'\n",
    "#CORPUS = 'aiml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_properties(filepath, sep='=', comment_char='#'):\n",
    "    '''\n",
    "    Read the file passed as parameter as a properties file.\n",
    "    '''\n",
    "    props = {}\n",
    "    with open(filepath, \"rt\") as f:\n",
    "        for line in f:\n",
    "            l = line.strip()\n",
    "            if l and not l.startswith(comment_char):\n",
    "                key_value = l.split(sep)\n",
    "                key = key_value[0].strip()\n",
    "                value = sep.join(key_value[1:]).strip().strip('\"') \n",
    "                props[key] = value \n",
    "    return props\n",
    "'''\n",
    "Save a dictionary as a properties file; use to remember the latest processed id.\n",
    "TODO store comments\n",
    "'''\n",
    "def save_properties(properties, filepath, sep='=', comment_char='#'):\n",
    "    with open(filepath, 'w') as f: \n",
    "        for key, value in properties.items(): \n",
    "            f.write('%s %s %s\\n' % (key, sep, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_properties = load_properties(f\"corpora/{CORPUS}.properties\")\n",
    "corpus_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_BASE = corpus_properties['corpus_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_BASE = f'{CORPUS_BASE}/pdf'\n",
    "PDF_ND_BASE = f'{CORPUS_BASE}/pdf_nd'\n",
    "JSON_BASE = f'{CORPUS_BASE}/json_raw/'\n",
    "\n",
    "if not os.path.exists(PDF_BASE):\n",
    "    raise Exception('Please download the corpus first.')\n",
    "\n",
    "if not os.path.exists(JSON_BASE):\n",
    "    raise Exception('Please convert the corpus to raw json first.')\n",
    "\n",
    "if not os.path.exists(JSON_BASE):\n",
    "    raise Exception('Please run filter_nd first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load papers metadata\n",
    "nl = 0\n",
    "metadata_records = []\n",
    "with open(\"arxiv-metadata-oai-snapshot.json\") as f1:\n",
    "    for line in f1:\n",
    "        #print(line)   \n",
    "        metadata_record = json.loads(line)\n",
    "        #print(metadata_record)\n",
    "        metadata_records.extend([metadata_record])\n",
    "        #nl+=1\n",
    "        #if (nl == 5): break\n",
    "\n",
    "#print(metadata_records)\n",
    "metadata_df = pd.DataFrame(metadata_records)\n",
    "metadata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for paper in the metadata_df\n",
    "def kaggle_search(paper_id):\n",
    "    row = metadata_df.loc[metadata_df['id'] == paper_id]\n",
    "    #print(row)\n",
    "    paper = None\n",
    "    try:\n",
    "        paper = {}\n",
    "        paper['id'] = row['id'].values[0]\n",
    "        paper['title'] = row['title'].values[0]\n",
    "        paper['versions'] = row['versions'].values[0]\n",
    "        paper['abstract'] = row['abstract'].values[0]\n",
    "        paper['license'] = row['license'].values[0]\n",
    "\n",
    "        latest_version = 'v1'\n",
    "        for version in paper['versions'] :\n",
    "            #v = json.loads(version)\n",
    "            if version['version'] > latest_version:\n",
    "                latest_version = version['version']\n",
    "        paper['latest_version'] = latest_version\n",
    "    except IndexError as ie:\n",
    "        print(ie)\n",
    "        print(f'Paper {paper_id} not found. Perhas should download a new metadata db version?')\n",
    "    \n",
    "    return paper\n",
    "\n",
    "#paper = kaggle_search('2212.09410')\n",
    "paper = kaggle_search('0704.0001')\n",
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_file(filename, content):\n",
    "    pathlib.Path(JSON_BASE+filename).write_bytes(content.encode('utf-8').strip())\n",
    "\n",
    "def save_abstract(title,content):\n",
    "    document_dict = dict()\n",
    "    filename = title+'.json'\n",
    "    document_dict['title'] = title\n",
    "    document_dict['text'] = content\n",
    "    document_dict['extraction_date'] = str(datetime.utcnow())\n",
    "    document_dict['num_pages'] = 1\n",
    "    json_object = json.dumps(document_dict) \n",
    "    write_json_file(filename,json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [f for f in listdir(PDF_BASE) if isfile(join(PDF_BASE, f))]\n",
    "print(f'Analyzing {len(pdf_files)} PDF files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_name in pdf_files:\n",
    "    pdf_id = '.'.join(pdf_name.split('.')[:2])\n",
    "    paper_id = pdf_id[:10]\n",
    "    paper = kaggle_search(paper_id)\n",
    "    if paper:\n",
    "        if 'nd' in paper['license']:\n",
    "            file_name = pdf_name.split(PDF_BASE)[0]\n",
    "            print(file_name)\n",
    "            print(paper['license'])\n",
    "            print(paper['abstract'])\n",
    "            save_abstract(file_name, paper['abstract'])\n",
    "            in_file_name = f'{PDF_BASE}/{file_name}'\n",
    "            out_file_name = f'{PDF_ND_BASE}/{file_name}'\n",
    "            pathlib.Path(in_file_name).rename(out_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [f for f in listdir(PDF_ND_BASE) if isfile(join(PDF_ND_BASE, f))]\n",
    "print(f'Analyzing {len(pdf_files)} PDF files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_name in pdf_files:\n",
    "    pdf_id = '.'.join(pdf_name.split('.')[:2])\n",
    "    paper_id = pdf_id[:10]\n",
    "    paper = kaggle_search(paper_id)\n",
    "    if paper:\n",
    "        if 'nd' in paper['license']:\n",
    "            file_name = pdf_name.split(PDF_ND_BASE)[0]\n",
    "            print(file_name)\n",
    "            print(paper['license'])\n",
    "            #print(paper['abstract'])\n",
    "            save_abstract(file_name, paper['abstract'])\n",
    "            #in_file_name = f'{PDF_BASE}/{file_name}'\n",
    "            #out_file_name = f'{PDF_ND_BASE}/{file_name}'\n",
    "            #pathlib.Path(in_file_name).rename(out_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
