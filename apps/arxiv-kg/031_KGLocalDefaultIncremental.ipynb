{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Index \n",
    "## Default llama index KG prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "from pyvis.network import Network\n",
    "\n",
    "import sys\n",
    "#kron extensions to llama_index to support openai compatible api\n",
    "sys.path.append('../llama-index/')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "import openai\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-48characterstofakeanopenaikey48charactersopenai0\"\n",
    "os.environ['OPENAI_API_BASE'] = \"http://10.0.0.222:30307/v1\"\n",
    "openai.api_key = \"sk-48characterstofakeanopenaikey48charactersopenai0\"\n",
    "openai.api_base = \"http://10.0.0.222:30307/v1\"\n",
    "\n",
    "model = \"Writer/camel-5b-hf\"\n",
    "#model = \"mosaicml/mpt-7b-instruct\"\n",
    "#model = \"mosaicml/mpt-30b-instruct\"\n",
    "\n",
    "#CORPUS = 'ArxivHealthcareNLP'\n",
    "CORPUS = 'arxiv_cl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'account': '@arxiv_cl@creative.ai',\n",
       " 'latest': '110803680085564152',\n",
       " 'corpus_base': '/home/arylwen/datasets/documents/arxiv_cl'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_properties(filepath, sep='=', comment_char='#'):\n",
    "    '''\n",
    "    Read the file passed as parameter as a properties file.\n",
    "    '''\n",
    "    props = {}\n",
    "    with open(filepath, \"rt\") as f:\n",
    "        for line in f:\n",
    "            l = line.strip()\n",
    "            if l and not l.startswith(comment_char):\n",
    "                key_value = l.split(sep)\n",
    "                key = key_value[0].strip()\n",
    "                value = sep.join(key_value[1:]).strip().strip('\"') \n",
    "                props[key] = value \n",
    "    return props\n",
    "\n",
    "corpus_properties = load_properties(f\"corpora/{CORPUS}.properties\")\n",
    "corpus_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index import StorageContext\n",
    "from llama_index import SimpleDirectoryReader, ServiceContext\n",
    "from llama_index import KnowledgeGraphIndex\n",
    "from llama_index.graph_stores import SimpleGraphStore \n",
    "from llama_index import load_index_from_storage \n",
    "from llama_index.langchain_helpers.text_splitter import SentenceSplitter\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "#extensions to llama_index to support openai compatible endpoints, e.g. llama-api\n",
    "from kron.llm_predictor.KronOpenAILLM import KronOpenAI\n",
    "from kron.llm_predictor.KronLLMPredictor import KronLLMPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_BASE = corpus_properties['corpus_base']\n",
    "TXT_BASE = f'{CORPUS_BASE}/text_cleaned/'\n",
    "PROCESSED_TXT_BASE = f'{CORPUS_BASE}/text_cleaned_out/'\n",
    "persist_path = f\"storage/{model.replace('/', '-')}-default\"\n",
    "\n",
    "#folder to save succesive versions of the pyvis graph\n",
    "HTML_FOLDER = f\"html/{model.replace('/', '-')}-default\"\n",
    "if not os.path.exists(HTML_FOLDER):\n",
    "    print(f'Creating {HTML_FOLDER}.')\n",
    "    os.makedirs(HTML_FOLDER)\n",
    "\n",
    "if not os.path.exists(PROCESSED_TXT_BASE):\n",
    "    print(f'Creating {PROCESSED_TXT_BASE}.')\n",
    "    os.makedirs(PROCESSED_TXT_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer/camel uses endoftext \n",
    "from llama_index.utils import globals_helper\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer = lambda text: enc.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "globals_helper._tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(TXT_BASE, filename_as_id=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_window=2048 num_output=384 is_chat_model=False model_name='unknown'\n"
     ]
    }
   ],
   "source": [
    "# define LLM\n",
    "#llm=OpenAI(temperature=0.01, model=model)\n",
    "llm=KronOpenAI(temperature=0.01, model=model)\n",
    "#chunk_size+prompt_length+expected length of returned triples must be less than max_tokens\n",
    "#llm.max_tokens = 274 #128-32\n",
    "#some sentences can be really long and the text spliter will enter an infinit loop\n",
    "#llm.max_tokens = 400 #256-64\n",
    "llm.max_tokens = 384 #192-48\n",
    "llm_predictor = KronLLMPredictor(llm)\n",
    "print(llm_predictor.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define TextSplitter\n",
    "text_splitter = SentenceSplitter(chunk_size=192, chunk_overlap=48, paragraph_separator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define NodeParser\n",
    "node_parser = SimpleNodeParser(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define ServiceContext\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, node_parser=node_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create pyvis graph\n",
    "def save_pyvis_network_graph(file_name):\n",
    "    #display all nodes\n",
    "    g = index.get_networkx_graph(limit = 6000)\n",
    "    net = Network(height='1000px', width='100%', notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "    net.from_nx(g)\n",
    "    html_name = f'{HTML_FOLDER}/{file_name}.html'\n",
    "    print(html_name)\n",
    "    net.show(html_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from storage/Writer-camel-5b-hf-default\n",
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Processing: 2302.08575v1.Foundation_Models_for_Natural_Language_Processing____Pre_trained___Language_Models_Integrating_Media.pdf.txt\n",
      "html/Writer-camel-5b-hf-default/2302.08575v1.Foundation_Models_for_Natural_Language_Processing____Pre_trained___Language_Models_Integrating_Media.pdf.txt.html\n",
      "html/Writer-camel-5b-hf-default/2302.08575v1.Foundation_Models_for_Natural_Language_Processing____Pre_trained___Language_Models_Integrating_Media.pdf.txt.html\n",
      "Processing: 2307.15002v1.Gzip_versus_bag_of_words_for_text_classification_with_KNN.pdf.txt\n",
      "html/Writer-camel-5b-hf-default/2307.15002v1.Gzip_versus_bag_of_words_for_text_classification_with_KNN.pdf.txt.html\n",
      "html/Writer-camel-5b-hf-default/2307.15002v1.Gzip_versus_bag_of_words_for_text_classification_with_KNN.pdf.txt.html\n",
      "Documents added in: 4504.9427263736725s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if os.path.exists(persist_path):\n",
    "    start = time.time()\n",
    "    print(f'Loading index from {persist_path}')\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=persist_path)\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context=storage_context, \n",
    "                                    service_context=service_context, \n",
    "                                    max_triplets_per_chunk=2,\n",
    "                                    show_progress = True)\n",
    "    ## add documents to index\n",
    "    #print(index)\n",
    "    #print(type(documents))\n",
    "    for d in documents:\n",
    "        file_name = pathlib.Path(d.id_).name\n",
    "        print(f'Processing: {file_name}')\n",
    "        #index the document: extract triples and inseart into the KG graph\n",
    "        index.insert(document = d)\n",
    "        #move the file to the processed folder\n",
    "        in_file_name = f'{TXT_BASE}/{file_name}'\n",
    "        processed_file_name = f'{PROCESSED_TXT_BASE}/{file_name}'\n",
    "        pathlib.Path(in_file_name).rename(processed_file_name)\n",
    "        #index is modified after each doc\n",
    "        save_pyvis_network_graph(file_name)\n",
    "        index.storage_context.persist(persist_dir=persist_path)\n",
    "    end = time.time()\n",
    "    print(f\"Documents added in: {end-start}s\")\n",
    "else:\n",
    "    print('No KGIndex found, starting fresh.')\n",
    "    graph_store = SimpleGraphStore()\n",
    "    storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "    # NOTE: can take a while! \n",
    "\n",
    "    start = time.time()\n",
    "    index = KnowledgeGraphIndex.from_documents(\n",
    "        documents,\n",
    "        max_triplets_per_chunk=2,\n",
    "        storage_context=storage_context,\n",
    "        service_context=service_context,\n",
    "    )\n",
    "    #move files to the processed files folder/s3/other location\n",
    "    for d in documents:\n",
    "        #d.id_ is the full path of the input file\n",
    "        file_name = pathlib.Path(d.id_).name\n",
    "        in_file_name = f'{TXT_BASE}/{file_name}'\n",
    "        processed_file_name = f'{PROCESSED_TXT_BASE}/{file_name}'\n",
    "        pathlib.Path(in_file_name).rename(processed_file_name)\n",
    "        save_pyvis_network_graph(file_name)\n",
    "    #save index TODO what if it fails - compensatory transaction\n",
    "    index.storage_context.persist(persist_dir=persist_path)\n",
    "    end = time.time()\n",
    "    print(f\"Knowledge Graph built in: {end-start}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
